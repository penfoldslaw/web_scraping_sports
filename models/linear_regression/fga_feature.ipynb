{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_usage_team\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "{ 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC', 'Shai Gilgeous-Alexander':'OKC'}\n",
    "{'Chris Paul': 'SAS',\"De'Aaron Fox\": 'SAS', \"Devin Vassell\": 'SAS',\"Harrison Barnes\": 'SAS'}\n",
    "\n",
    "player_names = {\"Payton Pritchard\": 'BOS'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "player_df, current_defense_stat = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "\n",
    "\n",
    "\n",
    "for player, df in player_df.items():\n",
    "    print(player)\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import numpy as np\n",
    "\n",
    "    df_X = df.drop(columns=['PTS','Date','Matchup','Team','Home/Away_game','W/L', 'Away', 'season', 'TEAM', 'season_defense'])\n",
    "\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df_X)\n",
    "\n",
    "    y = df['PTS']  # Replace with your actual target\n",
    "\n",
    "\n",
    "    # Define the grid search parameters for Lasso (L1 regularization)\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10]  # Different levels of regularization strength\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print best parameters\n",
    "    print(\"Best alpha:\", grid_search.best_params_)\n",
    "\n",
    "    X = pd.DataFrame(X, columns=df_X.columns)  # Convert back to DataFrame\n",
    "\n",
    "\n",
    "    # Get the best alpha\n",
    "    best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "    # Fit Lasso with the best alpha\n",
    "    best_lasso = Lasso(alpha=best_alpha)\n",
    "    best_lasso.fit(X, y)\n",
    "\n",
    "\n",
    "    # Get selected (non-zero) feature indices\n",
    "    selected_features = X.columns[best_lasso.coef_ != 0]\n",
    "    print(\"Selected features:\", selected_features)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # display(y_test)\n",
    "\n",
    "    timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "    train_data = df[df['Date_in_Seconds'] < timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "    test_data =  df[df['Date_in_Seconds'] >= timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "\n",
    "    X_train = train_data[selected_features]\n",
    "    y_train = train_data['FGM']\n",
    "    X_test = test_data[selected_features]\n",
    "    y_test = test_data['FGM']\n",
    "\n",
    "\n",
    "\n",
    "    # Reduce X to selected features only\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "\n",
    "\n",
    "    # Retrain Lasso only on selected features\n",
    "    final_lasso = Lasso(alpha=best_alpha)\n",
    "    final_lasso.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predict on the test set using the reduced feature set\n",
    "    y_pred = final_lasso.predict(X_test_selected)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(\"Final RMSE using selected features:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_usage_team\n",
    "\n",
    "player_names = {\n",
    "    \"Jayson Tatum\": \"BOS\",\n",
    "    # # \"Nikola Jokic\": \"DEN\",\n",
    "    # \"Jamal Murray\": \"DEN\",\n",
    "    # \"Jaylen Brown\": \"BOS\",\n",
    "    # \"Derrick White\": \"BOS\",\n",
    "    # \"Payton Pritchard\": \"BOS\",\n",
    "    # \"Michael Porter Jr.\": \"DEN\",\n",
    "    # \"Russell Westbrook\": \"DEN\",\n",
    "    # \"Christian Braun\": \"DEN\",\n",
    "    # \"Al Horford\": \"BOS\",\n",
    "    # # \"Julian Strawther\": \"DEN\",\n",
    "    # \"Sam Hauser\": \"BOS\",\n",
    "    # \"Zeke Nnaji\": \"DEN\",\n",
    "    # \"Luke Kornet\": \"BOS\"\n",
    "}\n",
    "date_list = [\"2023-24\",\"2024-25\"]\n",
    "# usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "stats_path = {\n",
    "    'usage_path':'D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv',\n",
    "    'catch_shoot':\"D:/nba_tracking_data_csv/nba_csv_{date}/catch_shoot_content.csv\",\n",
    "    'drives':\"D:/nba_tracking_data_csv/nba_csv_{date}/drives_content.csv\",\n",
    "    'elbow_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/elbow_touch_content.csv\",\n",
    "    'paint_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/paint_touch_content.csv\",\n",
    "    'passing':\"D:/nba_tracking_data_csv/nba_csv_{date}/passing_content.csv\",\n",
    "    'pullup':\"D:/nba_tracking_data_csv/nba_csv_{date}/pullup_content.csv\",\n",
    "    'shooting_efficiency':\"D:/nba_tracking_data_csv/nba_csv_{date}/shooting_efficiency_content.csv\",\n",
    "    'touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/touches_content.csv\",\n",
    "    'tracking_post_ups_content':\"D:/nba_tracking_data_csv/nba_csv_{date}/tracking_post_ups_content.csv\"\n",
    "}\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "player_df, current_defense_stat = his_usage_team(player_names, date_list, stats_path, player_base_path, defense_base_path)\n",
    "\n",
    "for player, df in player_df.items():\n",
    "    display(player)\n",
    "    display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def select_features(player_names, date_list, usage_path, player_base_path, defense_base_path, target):\n",
    "    player_df, _ = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    \n",
    "    selected_features_dict = {}\n",
    "    \n",
    "    max_features_player = None\n",
    "    max_features = 0\n",
    "\n",
    "    for player, df in player_df.items():\n",
    "        df_X = df.drop(columns=[target, 'Date', 'Matchup', 'Team', 'Home/Away_game', 'W/L', 'Away', 'season', 'TEAM', 'season_defense'])\n",
    "        \n",
    "        # Apply StandardScaler to scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(df_X)\n",
    "        y = df[target]  # Target variable\n",
    "        \n",
    "        # Grid search parameters for Lasso\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "        \n",
    "        # Use GridSearchCV to find the best alpha\n",
    "        grid_search = GridSearchCV(Lasso(max_iter=50000), param_grid, cv=5, scoring='r2')  # Increase max_iter here\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best alpha and fit Lasso\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_lasso = Lasso(alpha=best_alpha, max_iter=50000)  # Ensure enough iterations for convergence\n",
    "        best_lasso.fit(X, y)\n",
    "        \n",
    "        # Select non-zero coefficient features\n",
    "        X = pd.DataFrame(X, columns=df_X.columns)\n",
    "        selected_features = X.columns[best_lasso.coef_ != 0].tolist()\n",
    "        \n",
    "        # Store selected features\n",
    "        selected_features_dict[player] = selected_features\n",
    "        \n",
    "        # Track the player with the most features\n",
    "        if len(selected_features) > max_features:\n",
    "            max_features = len(selected_features)\n",
    "            max_features_player = player\n",
    "\n",
    "    # If a player has no selected features, assign the features of the player with the most features\n",
    "    for player in selected_features_dict:\n",
    "        if not selected_features_dict[player]:  # If empty\n",
    "            selected_features_dict[player] = selected_features_dict.get(max_features_player, [])\n",
    "\n",
    "    return selected_features_dict\n",
    "\n",
    "\n",
    "\n",
    "player_names = {\n",
    "    \"Devin Booker\": \"PHX\",\n",
    "    \"Anthony Edwards\": \"MIN\",\n",
    "    \"Kevin Durant\": \"PHX\",\n",
    "    \"Naz Reid\": \"MIN\",\n",
    "    \"Julius Randle\": \"MIN\",\n",
    "    \"Bradley Beal\": \"PHX\",\n",
    "    \"Bol Bol\": \"PHX\",\n",
    "    \"Donte DiVincenzo\": \"MIN\",\n",
    "    \"Jaden McDaniels\": \"MIN\",\n",
    "    \"Nick Richards\": \"PHX\",\n",
    "    \"Mike Conley\": \"MIN\"\n",
    "}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "stats_path = {\n",
    "    'usage_path':'D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv',\n",
    "    'catch_shoot':\"D:/nba_tracking_data_csv/nba_csv_{date}/catch_shoot_content.csv\",\n",
    "    'drives':\"D:/nba_tracking_data_csv/nba_csv_{date}/drives_content.csv\",\n",
    "    'elbow_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/elbow_touch_content.csv\",\n",
    "    'paint_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/paint_touch_content.csv\",\n",
    "    'passing':\"D:/nba_tracking_data_csv/nba_csv_{date}/passing_content.csv\",\n",
    "    'pullup':\"D:/nba_tracking_data_csv/nba_csv_{date}/pullup_content.csv\",\n",
    "    'shooting_efficiency':\"D:/nba_tracking_data_csv/nba_csv_{date}/shooting_efficiency_content.csv\",\n",
    "    'touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/touches_content.csv\",\n",
    "    'tracking_post_ups_content':\"D:/nba_tracking_data_csv/nba_csv_{date}/tracking_post_ups_content.csv\"\n",
    "}\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "feature_dic = select_features(player_names, date_list, stats_path, player_base_path, defense_base_path,'FGA')\n",
    "\n",
    "for player, features in feature_dic.items():\n",
    "    # print(player)\n",
    "    features = feature_dic[player] \n",
    "    print(player,':',features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for shai\n",
    "# 'MIN_x', 'FGM', 'FG%', '3PA', 'OREB', 'REB', 'RANK'\n",
    "\n",
    "from feature_function import  select_features\n",
    "from data_functions import his_player_defense_data, current_player_defense_data, build_data_path, his_usage_team\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from scipy.stats import linregress\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# player_names = {\"Payton Pritchard\": 'BOS'}\n",
    "player_names = {\n",
    "    \"Shai Gilgeous-Alexander\": \"OKC\",\n",
    "    \"Jayson Tatum\": \"BOS\",\n",
    "    \"Jaylen Brown\": \"BOS\",\n",
    "    \"Kristaps Porzingis\": \"BOS\",\n",
    "    \"Chet Holmgren\": \"OKC\",\n",
    "    \"Derrick White\": \"BOS\",\n",
    "    \"Isaiah Hartenstein\": \"OKC\",\n",
    "    \"Luguentz Dort\": \"OKC\",\n",
    "    \"Jrue Holiday\": \"BOS\",\n",
    "    \"LaMelo Ball\": \"CHA\",\n",
    "    \"Miles Bridges\": \"CHA\",\n",
    "    \"Trae Young\": \"ATL\",\n",
    "    \"Dyson Daniels\": \"ATL\",\n",
    "    \"Mark Williams\": \"CHA\",\n",
    "    \"Onyeka Okongwu\": \"ATL\",\n",
    "    \"Zaccharie Risacher\": \"ATL\",\n",
    "    \"Mouhamed Gueye\": \"ATL\",\n",
    "    \"DaQuan Jeffries\": \"CHA\",\n",
    "    \"Josh Green\": \"CHA\",\n",
    "    \"Scottie Barnes\": \"TOR\",\n",
    "    \"Quentin Grimes\": \"PHI\",\n",
    "    \"Kelly Oubre Jr.\": \"TOR\",\n",
    "    \"Jakob Poeltl\": \"TOR\",\n",
    "    \"Jamal Shead\": \"TOR\",\n",
    "    \"Andre Drummond\": \"PHI\",\n",
    "    \"Guerschon Yabusele\": \"PHI\",\n",
    "    \"Justin Edwards\": \"PHI\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "stats_path = {\n",
    "    'usage_path':'D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv',\n",
    "    'catch_shoot':\"D:/nba_tracking_data_csv/nba_csv_{date}/catch_shoot_content.csv\",\n",
    "    'drives':\"D:/nba_tracking_data_csv/nba_csv_{date}/drives_content.csv\",\n",
    "    'elbow_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/elbow_touch_content.csv\",\n",
    "    'paint_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/paint_touch_content.csv\",\n",
    "    'passing':\"D:/nba_tracking_data_csv/nba_csv_{date}/passing_content.csv\",\n",
    "    'pullup':\"D:/nba_tracking_data_csv/nba_csv_{date}/pullup_content.csv\",\n",
    "    'shooting_efficiency':\"D:/nba_tracking_data_csv/nba_csv_{date}/shooting_efficiency_content.csv\",\n",
    "    'touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/touches_content.csv\",\n",
    "    'tracking_post_ups_content':\"D:/nba_tracking_data_csv/nba_csv_{date}/tracking_post_ups_content.csv\"\n",
    "}\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "def prediction(player_names: dict, date_list: list, stats_path, player_base_path, defense_base_path, schedule_base_path,selected_feature_target, prediction_target):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list, stats_path, player_base_path, defense_base_path)\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import pandas\n",
    "\n",
    "    # this is the function that will be used to select the features for the model prints out the player and the best features to use\n",
    "    feature_dic = select_features(player_names, date_list, stats_path, player_base_path, defense_base_path,selected_feature_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        # Get schedule data for the player's team\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # Get player-specific prediction data\n",
    "\n",
    "        df = fga_prediction_data[player]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        features = feature_dic[player] \n",
    "        # print(features)\n",
    "        target = prediction_target\n",
    "\n",
    "        timestamp = int(pd.Timestamp('2025-02-26').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]\n",
    "        test_data = df[df['Date_in_Seconds'] >= timestamp]\n",
    "\n",
    "        # display(test_data)\n",
    "        if not features:  # If feature_columns is an empty list\n",
    "            print(f\"Skipping training: No selected {target} features.\")\n",
    "            sys.exit(1) \n",
    "\n",
    "        X_train = train_data[features].fillna(0)\n",
    "        y_train = train_data[target].fillna(0)\n",
    "        X_test = test_data[features].fillna(0)\n",
    "        y_test = test_data[target].fillna(0)\n",
    "\n",
    "        # print(f\"X_train shape: {X_train.shape}\")\n",
    "        # print(f\"y_train shape: {y_train.shape}\")\n",
    "        # print(X_train.head())  # View first few rows\n",
    "        # print(y_train.head())  # View first few rows\n",
    "\n",
    "        # print(features)  # Check selected feature names\n",
    "        # print(train_data.columns)  # See available columns\n",
    "\n",
    "\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # print(f\"{player}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        # EWMA calculation for minutes\n",
    "        alpha = 0.2\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "        last_actual = df['MIN_x'].iloc[-1]\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = round(next_value, 2)\n",
    "\n",
    "\n",
    "        # Exclude columns\n",
    "        exclude_features = ['RANK', 'OffRtg', 'W', 'L', \n",
    "            'DefRtg','NetRtg', 'AST%', 'AST/TO', 'ASTRatio',\n",
    "            'OREB%', 'DREB%', 'REB%', 'TOV%' , 'eFG%', 'TS%', 'PACE',\n",
    "            'POSS', 'TEAM', 'PIE']\n",
    "        \n",
    "        exclude_features_schedule = ['home_away', 'schedule_team', 'DATE', 'location', 'season_defense']\n",
    "\n",
    "        # Get defensive stats for the scheduled team\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "        # df_defense = df_defense.merge(schedule_df, left_on='TEAM', right_on = 'schedule_team', how='outer', suffixes=('', '_DROP'))\n",
    "        # df_defense = df_defense.drop(columns=[col for col in df_defense.columns if col.endswith('_DROP')])\n",
    "        # df_defense= df_defense.fillna(0)\n",
    "\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1]\n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, exclude_features]\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "\n",
    "\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "\n",
    "\n",
    "        schedule_values = {feature: df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, feature].values[0] \n",
    "                for feature in exclude_features if feature in df_for_schedule.columns}\n",
    "\n",
    "\n",
    "        \n",
    "        rolling_features = [col for col in features  if col not in exclude_features]\n",
    "        # display(rolling_features)\n",
    "\n",
    "        # df = df[df['Date_in_Seconds'] >= timestamp]\n",
    "        # # display(df)\n",
    "\n",
    "        for col in rolling_features:\n",
    "            df[f'{col}'] = df[col].rolling(window=20).mean().fillna(0).astype(int)\n",
    "\n",
    "        df_last_rolling = df.iloc[[-1]][[f'{col}' for col in rolling_features]]\n",
    "\n",
    "        df_last_rolling = df_last_rolling.reset_index(drop=True)\n",
    "\n",
    "        for value in features:\n",
    "            if value in exclude_features:\n",
    "                # print(f'This is the value {value}')\n",
    "                df_last_rolling[value] = schedule_values.get(value)\n",
    "                # df_last_rolling[value] = schedule_df[value].iloc[0]\n",
    "\n",
    "        for value in features:\n",
    "            if value in exclude_features_schedule:\n",
    "                # print(f'This is the value {value}')\n",
    "                # df_last_rolling[value] = schedule_values.get(value)\n",
    "                df_last_rolling[value] = schedule_df[value].iloc[0]        \n",
    "\n",
    "\n",
    "\n",
    "        df_last_rolling = df_last_rolling.reindex(columns=features)\n",
    "\n",
    "        X_future = df_last_rolling\n",
    "\n",
    "        # display(X_future.head(10))\n",
    "        # Step 1: Calculate mean and standard deviation of the target variable (PTS, REB, etc.)\n",
    "        mean_target = y_train.mean()\n",
    "        std_target = y_train.std()\n",
    "\n",
    "        # Step 2: Define reasonable bounds (e.g., within 3 standard deviations)\n",
    "        lower_bound = mean_target - 3 * std_target\n",
    "        upper_bound = mean_target + 3 * std_target\n",
    "\n",
    "        \n",
    "\n",
    "        # future predictions happens here\n",
    "        future_predictions = model.predict(X_future).astype('int')\n",
    "\n",
    "        future_predictions = np.clip(future_predictions, lower_bound, upper_bound).astype('int')\n",
    "\n",
    "\n",
    "\n",
    "        # creating rolling mean average\n",
    "        df[f\"Rolling_Mean_{target}\"] = df[target].rolling(window=20).mean()\n",
    "        df[f\"Rolling_Std_{target}\"] = df[target].rolling(window=20).std()\n",
    "        df[f\"Rolling_CV_{target}\"] = df[f\"Rolling_Std_{target}\"] / df[f\"Rolling_Mean_{target}\"]\n",
    "\n",
    "        rounded_future_prediction = abs(future_predictions[0])\n",
    "\n",
    "        # print(player)\n",
    "        # display(X_future.head(10))\n",
    "        # print(player, target, rounded_future_prediction)\n",
    "        # display(df[[f\"Rolling_CV_{target}\"]].tail(1))\n",
    "\n",
    "        if pd.isna(df[f\"Rolling_CV_{target}\"].iloc[-1]) or np.isinf(df[f\"Rolling_CV_{target}\"].iloc[-1]):\n",
    "            df.loc[df.index[-1], f\"Rolling_CV_{target}\"] = 0\n",
    "\n",
    "        rolling_cv = df[f\"Rolling_CV_{target}\"].iloc[-1]\n",
    "        highest_cv_seen = df[f\"Rolling_CV_{target}\"].max()\n",
    "\n",
    "        cv_fluctuate = rolling_cv * rounded_future_prediction\n",
    "\n",
    "        if cv_fluctuate > rounded_future_prediction:\n",
    "            cv_low_prediction = abs(cv_fluctuate - rounded_future_prediction)\n",
    "\n",
    "        cv_low_prediction = abs(rounded_future_prediction- cv_fluctuate)\n",
    "        cv_high_prediction = rounded_future_prediction + cv_fluctuate\n",
    "\n",
    "        player_prediction = f\"{cv_low_prediction.astype('int')} to {rounded_future_prediction}\"\n",
    "\n",
    "        \n",
    "\n",
    "        if rolling_cv > 1:\n",
    "            confidence_score = max(0, 1 - (rolling_cv / highest_cv_seen))\n",
    "        else:\n",
    "            confidence_score = 1 - rolling_cv  # More stability → Higher confidence\n",
    "\n",
    "        confidence_score_percentage = round(confidence_score * 100, 2)\n",
    "\n",
    "\n",
    "        lower_bound, upper_bound = cv_low_prediction, rounded_future_prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Get last 10 games\n",
    "        recent_games = df[target].tail(4)\n",
    "        \n",
    "\n",
    "\n",
    "        # Fit a linear regression (x = game number, y = points)\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(range(len(recent_games)), recent_games)\n",
    "\n",
    "        long_term_cv = df[\"PTS\"].rolling(10).std() / df[\"PTS\"].rolling(10).mean()\n",
    "\n",
    "        # Set dynamic base threshold (scaled by long-term CV)\n",
    "        base_threshold = max(0.2, min(0.6, 0.3 + 0.2 * long_term_cv.iloc[-1]))\n",
    "\n",
    "        # Compute dynamic middle threshold (adjusted for rolling CV)\n",
    "        middle_threshold = max(0.2, min(0.8, base_threshold * (1 + rolling_cv)))\n",
    "        \n",
    "        # Check if the slope is close to zero (i.e., in the middle)\n",
    "        if -middle_threshold <= slope <= middle_threshold:\n",
    "            trend_status = \"stable\"\n",
    "        elif slope > 0:\n",
    "            trend_status = \"trending up\"\n",
    "        else:\n",
    "            trend_status = \"trending down\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### this is for safebet column ############\n",
    "        import math\n",
    "        # Step 1: Calculate the midpoint of the range\n",
    "        midpoint = (lower_bound + upper_bound) / 2\n",
    "        midpoint = math.floor(midpoint)\n",
    "    \n",
    "        \n",
    "        # Step 2: Adjust the prediction based on confidence score\n",
    "        if confidence_score_percentage > 60:\n",
    "            # High confidence - stick closer to midpoint\n",
    "            if trend_status == \"trending up\":\n",
    "                # Trending up - lean towards the higher end\n",
    "                exact_point = round(midpoint)\n",
    "            elif trend_status == \"trending down\":\n",
    "                # Trending down - lean towards the lower end\n",
    "                exact_point = lower_bound\n",
    "            else:\n",
    "                # Stable - pick midpoint or the closest round number\n",
    "                exact_point = round(midpoint)\n",
    "        else:\n",
    "            # Low confidence - lean more conservatively towards the edges\n",
    "            if trend_status == \"trending up\":\n",
    "                # Trending up - lean towards the higher end\n",
    "                exact_point = round(midpoint + 1)  # Slight bias to upper end\n",
    "            elif trend_status == \"trending down\":\n",
    "                # Trending down - lean towards the lower end\n",
    "                exact_point = round(midpoint - 1)  # Slight bias to lower end\n",
    "            else:\n",
    "                # Stable - pick midpoint but be cautious (lean lower)\n",
    "                exact_point = round(midpoint - 1)\n",
    "\n",
    "        exact_point = int(exact_point)\n",
    "\n",
    "        if exact_point == -1:\n",
    "            exact_point = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # Step 1: Define Over/Under Strategy\n",
    "        # if confidence_score_percentage >= 75:  # High confidence range\n",
    "        #     safe_over = lower_bound + 1  # Safe Over bet\n",
    "        #     safe_under = upper_bound + 1  # Safe Under bet\n",
    "        # elif confidence_score_percentage >= 50:  # Medium confidence range\n",
    "        #     safe_over = lower_bound + 2  # Slightly looser Over bet\n",
    "        #     safe_under = upper_bound  # Slightly looser Under bet\n",
    "        # else:  # Low confidence, more conservative bets\n",
    "        #     safe_over = lower_bound  # Conservative Over bet\n",
    "        #     safe_under = upper_bound  # Conservative Under bet\n",
    "        \n",
    "        # safe_over = int(safe_over)\n",
    "        # safe_under = int(safe_under)\n",
    "\n",
    "        # # Step 2: Adjust based on trend\n",
    "        # if trend_status == \"trending up\":\n",
    "        #     best_bet = f\"Over {safe_over}+\"  # Lean towards Over\n",
    "        # elif trend_status == \"trending down\":\n",
    "        #     best_bet = f\" over {safe_under}+\"  # Lean towards Under\n",
    "        # else:\n",
    "        #     best_bet = f\"Safe Over: {safe_over}+, risky Under: {safe_under}+\"\n",
    "\n",
    "                                                                   \n",
    "\n",
    "\n",
    "        # display(df.head(30))\n",
    "\n",
    "        fga_prediction_results[player] = [player_prediction,confidence_score_percentage, exact_point]\n",
    "        if target == 'FGA':\n",
    "            target = 'PTS'\n",
    "        df_results = pd.DataFrame.from_dict(fga_prediction_results, orient='index', columns=[target,f'confidence_level_{target}' ,  f'safebet_{target}'])\n",
    "        # Reset index and rename it properly\n",
    "        df_results.reset_index(inplace=True)\n",
    "        df_results.rename(columns={'index': 'Player'}, inplace=True)\n",
    "        df_results.to_csv(f'{target}_output.csv', index=False)\n",
    "        # display(df_results)\n",
    "\n",
    "\n",
    "    return   df_results\n",
    "\n",
    "results_reb = prediction(player_names, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'REB','REB')\n",
    "results_ast = prediction(player_names, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'AST','AST')\n",
    "results_pts = prediction(player_names, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'PTS','FGA')\n",
    "results_3pm = prediction(player_names, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'3PM','3PM')\n",
    "results_pts = results_pts.rename(columns={'FGA': 'PTS'})\n",
    "\n",
    "\n",
    "\n",
    "display(results_reb)\n",
    "display(results_ast)\n",
    "display(results_pts)\n",
    "display(results_3pm)\n",
    "\n",
    "df_merged = results_reb.merge(results_ast, on='Player', suffixes=('_reb', '_ast')) \\\n",
    "    .merge(results_pts, on='Player', suffixes=('_pts','extra_pts')) \\\n",
    "    .merge(results_3pm, on='Player', suffixes=('_pts','_3pm'))\n",
    "\n",
    "\n",
    "display(df_merged)\n",
    "\n",
    "\n",
    "# df_merged['total_points'] = df_merged[['PTS', 'AST', 'REB']].sum(axis=1)\n",
    "# # df_merged = df_merged.rename(columns={'FGA': 'PTS'})\n",
    "\n",
    "# display(df_merged[['Player','total_points']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "# # Sample data\n",
    "# data = [\n",
    "#     [\"Shai Gilgeous-Alexander\", \"1 to 4\", 42.62, 1, \"3 to 5\", 64.37, 4, \"20 to 21\", 97.83, 20, \"1 to 3\", 54.12, 1],\n",
    "#     [\"Jayson Tatum\", \"3 to 6\", 59.60, 3, \"2 to 4\", 55.38, 2, \"19 to 20\", 96.93, 19, \"2 to 4\", 56.67, 4],\n",
    "#     # Add more rows as necessary...\n",
    "# ]\n",
    "\n",
    "# # Create a DataFrame\n",
    "# columns = [\"Player\", \"REB\", \"confidence_level_REB\", \"safebet_REB\", \n",
    "#            \"AST\", \"confidence_level_AST\", \"safebet_AST\", \n",
    "#            \"PTS\", \"confidence_level_PTS\", \"safebet_PTS\", \n",
    "#            \"3PM\", \"confidence_level_3PM\", \"safebet_3PM\"]\n",
    "# df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df = df_merged\n",
    "\n",
    "# Function to create parlays\n",
    "def create_parlays(df):\n",
    "    parlays = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        player = row[\"Player\"]\n",
    "        \n",
    "        # Collect the stats and confidence levels in separate categories\n",
    "        stats = {\n",
    "            \"REB\": (row[\"REB\"], row[\"confidence_level_REB\"]),\n",
    "            \"AST\": (row[\"AST\"], row[\"confidence_level_AST\"]),\n",
    "            \"PTS\": (row[\"PTS\"], row[\"confidence_level_PTS\"]),\n",
    "            \"3PM\": (row[\"3PM\"], row[\"confidence_level_3PM\"]),\n",
    "        }\n",
    "        \n",
    "        # Sort stats by confidence level (highest first)\n",
    "        sorted_stats = sorted(stats.items(), key=lambda x: x[1][1], reverse=True)\n",
    "        \n",
    "        # Add a new parlay based on the sorted stats while ensuring no player has all 4 stats in one parlay\n",
    "        # Pick the highest confidence for each stat, but never all 4\n",
    "        selected_stats = []\n",
    "        \n",
    "        for stat, (value, confidence) in sorted_stats:\n",
    "            if stat not in [s[0] for s in selected_stats]:  # Ensure no duplicate stat types in the parlay\n",
    "                selected_stats.append((stat, value, confidence))\n",
    "                \n",
    "            if len(selected_stats) == 3:  # Stop after selecting 3 unique stats\n",
    "                break\n",
    "        \n",
    "        parlays.append({\n",
    "            \"Player\": player,\n",
    "            \"Parlay Stats\": selected_stats,\n",
    "            \"Total Confidence\": sum([s[2] for s in selected_stats])  # Sum of confidence levels\n",
    "        })\n",
    "    \n",
    "    return parlays\n",
    "\n",
    "# Create parlays\n",
    "parlays = create_parlays(df)\n",
    "\n",
    "# Print out parlays\n",
    "for parlay in parlays:\n",
    "    print(f\"Player: {parlay['Player']}\")\n",
    "    for stat, value, confidence in parlay[\"Parlay Stats\"]:\n",
    "        print(f\"  {stat}: {value} (Confidence: {confidence}%)\")\n",
    "    print(f\"  Total Confidence: {parlay['Total Confidence']}%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced & High Confidence:\n",
      "Shai Gilgeous-Alexander (PTS) - 20 to 21 (Confidence: 97.83%) | Safebet: 20\n",
      "Jayson Tatum (PTS) - 19 to 20 (Confidence: 96.93%) | Safebet: 19\n",
      "Jaylen Brown (PTS) - 13 to 17 (Confidence: 77.1%) | Safebet: 15\n",
      "Kristaps Porzingis (PTS) - 9 to 13 (Confidence: 76.92%) | Safebet: 9\n",
      "Chet Holmgren (PTS) - 6 to 10 (Confidence: 60.68%) | Safebet: 8\n",
      "Derrick White (PTS) - 11 to 12 (Confidence: 95.54%) | Safebet: 11\n",
      "Isaiah Hartenstein (3PM) - 0 to 0 (Confidence: 100.0%) | Safebet: 0\n",
      "Luguentz Dort (PTS) - 5 to 8 (Confidence: 62.97%) | Safebet: 6\n",
      "Jrue Holiday (PTS) - 5 to 6 (Confidence: 91.02%) | Safebet: 5\n",
      "LaMelo Ball (PTS) - 16 to 19 (Confidence: 88.64%) | Safebet: 17\n",
      "Miles Bridges (PTS) - 13 to 18 (Confidence: 75.13%) | Safebet: 13\n",
      "Trae Young (PTS) - 13 to 18 (Confidence: 72.83%) | Safebet: 15\n",
      "Dyson Daniels (PTS) - 8 to 11 (Confidence: 81.1%) | Safebet: 9\n",
      "Mark Williams (3PM) - 0 to 0 (Confidence: 100.0%) | Safebet: 0\n",
      "Onyeka Okongwu (PTS) - 4 to 7 (Confidence: 68.59%) | Safebet: 5\n",
      "Zaccharie Risacher (PTS) - 6 to 10 (Confidence: 69.97%) | Safebet: 8\n",
      "Mouhamed Gueye (PTS) - 1 to 4 (Confidence: 47.6%) | Safebet: 1\n",
      "DaQuan Jeffries (PTS) - 1 to 3 (Confidence: 49.7%) | Safebet: 3\n",
      "Josh Green (PTS) - 2 to 5 (Confidence: 58.07%) | Safebet: 2\n",
      "Scottie Barnes (PTS) - 15 to 16 (Confidence: 96.97%) | Safebet: 15\n",
      "Quentin Grimes (PTS) - 4 to 10 (Confidence: 49.71%) | Safebet: 8\n",
      "Kelly Oubre Jr. (PTS) - 12 to 13 (Confidence: 92.62%) | Safebet: 12\n",
      "Jakob Poeltl (3PM) - 0 to 0 (Confidence: 100.0%) | Safebet: 0\n",
      "Jamal Shead (PTS) - 4 to 7 (Confidence: 61.67%) | Safebet: 5\n",
      "Andre Drummond (PTS) - 4 to 5 (Confidence: 87.37%) | Safebet: 4\n",
      "Guerschon Yabusele (PTS) - 3 to 7 (Confidence: 55.76%) | Safebet: 4\n",
      "Justin Edwards (PTS) - 4 to 7 (Confidence: 61.76%) | Safebet: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "More Risk, Higher Payout:\n",
      "Shai Gilgeous-Alexander (AST) - 3 to 5 (Confidence: 64.37%) | Safebet: 4\n",
      "Jayson Tatum (REB) - 3 to 6 (Confidence: 59.6%) | Safebet: 3\n",
      "Jaylen Brown (REB) - 3 to 5 (Confidence: 63.06%) | Safebet: 4\n",
      "Kristaps Porzingis (REB) - 3 to 6 (Confidence: 63.47%) | Safebet: 3\n",
      "Chet Holmgren (REB) - 3 to 7 (Confidence: 44.96%) | Safebet: 4\n",
      "Derrick White (3PM) - 2 to 5 (Confidence: 49.95%) | Safebet: 2\n",
      "Isaiah Hartenstein (PTS) - 3 to 6 (Confidence: 64.93%) | Safebet: 4\n",
      "Luguentz Dort (REB) - 1 to 3 (Confidence: 40.48%) | Safebet: 3\n",
      "Jrue Holiday (REB) - 2 to 4 (Confidence: 63.31%) | Safebet: 3\n",
      "LaMelo Ball (AST) - 2 to 5 (Confidence: 57.03%) | Safebet: 4\n",
      "Miles Bridges (REB) - 4 to 7 (Confidence: 68.32%) | Safebet: 4\n",
      "Trae Young (AST) - 7 to 11 (Confidence: 65.19%) | Safebet: 7\n",
      "Dyson Daniels (AST) - 3 to 5 (Confidence: 63.75%) | Safebet: 4\n",
      "Mark Williams (PTS) - 6 to 9 (Confidence: 67.52%) | Safebet: 7\n",
      "Onyeka Okongwu (REB) - 5 to 9 (Confidence: 66.63%) | Safebet: 5\n",
      "Zaccharie Risacher (3PM) - 0 to 2 (Confidence: 24.97%) | Safebet: 0\n",
      "Mouhamed Gueye (AST) - 0 to 1 (Confidence: 19.51%) | Safebet: 0\n",
      "DaQuan Jeffries (3PM) - 0 to 0 (Confidence: 36.57%) | Safebet: 0\n",
      "Josh Green (REB) - 0 to 2 (Confidence: 35.76%) | Safebet: 2\n",
      "Scottie Barnes (AST) - 1 to 3 (Confidence: 65.49%) | Safebet: 1\n",
      "Quentin Grimes (REB) - 0 to 2 (Confidence: 36.12%) | Safebet: 0\n",
      "Kelly Oubre Jr. (REB) - 2 to 5 (Confidence: 44.73%) | Safebet: 2\n",
      "Jakob Poeltl (PTS) - 7 to 8 (Confidence: 92.8%) | Safebet: 7\n",
      "Jamal Shead (AST) - 1 to 3 (Confidence: 49.77%) | Safebet: 1\n",
      "Andre Drummond (AST) - 0 to 0 (Confidence: 46.54%) | Safebet: 0\n",
      "Guerschon Yabusele (REB) - 1 to 4 (Confidence: 47.41%) | Safebet: 1\n",
      "Justin Edwards (REB) - 1 to 3 (Confidence: 47.15%) | Safebet: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "Safe & Consistent Play:\n",
      "Shai Gilgeous-Alexander (3PM) - 1 to 3 (Confidence: 54.12%) | Safebet: 1\n",
      "Jayson Tatum (3PM) - 2 to 4 (Confidence: 56.67%) | Safebet: 4\n",
      "Jaylen Brown (AST) - 1 to 3 (Confidence: 55.49%) | Safebet: 1\n",
      "Kristaps Porzingis (3PM) - 1 to 3 (Confidence: 39.68%) | Safebet: 1\n",
      "Chet Holmgren (AST) - 0 to 0 (Confidence: 15.39%) | Safebet: 0\n",
      "Derrick White (AST) - 1 to 3 (Confidence: 47.91%) | Safebet: 3\n",
      "Isaiah Hartenstein (REB) - 5 to 10 (Confidence: 58.01%) | Safebet: 6\n",
      "Luguentz Dort (AST) - 0 to 0 (Confidence: 33.97%) | Safebet: 0\n",
      "Jrue Holiday (AST) - 3 to 8 (Confidence: 39.31%) | Safebet: 4\n",
      "LaMelo Ball (3PM) - 1 to 3 (Confidence: 47.78%) | Safebet: 1\n",
      "Miles Bridges (AST) - 1 to 3 (Confidence: 40.31%) | Safebet: 1\n",
      "Trae Young (REB) - 1 to 2 (Confidence: 51.39%) | Safebet: 2\n",
      "Dyson Daniels (REB) - 3 to 5 (Confidence: 62.81%) | Safebet: 3\n",
      "Mark Williams (REB) - 6 to 10 (Confidence: 67.13%) | Safebet: 6\n",
      "Onyeka Okongwu (3PM) - 1 to 2 (Confidence: 66.01%) | Safebet: 1\n",
      "Zaccharie Risacher (REB) - 0 to 2 (Confidence: 23.91%) | Safebet: 2\n",
      "Mouhamed Gueye (REB) - 0 to 3 (Confidence: 17.69%) | Safebet: 0\n",
      "DaQuan Jeffries (REB) - 0 to 1 (Confidence: 11.3%) | Safebet: 0\n",
      "Josh Green (3PM) - 0 to 2 (Confidence: 28.41%) | Safebet: 0\n",
      "Scottie Barnes (REB) - 2 to 5 (Confidence: 49.41%) | Safebet: 2\n",
      "Quentin Grimes (3PM) - 0 to 1 (Confidence: 31.98%) | Safebet: 1\n",
      "Kelly Oubre Jr. (AST) - 1 to 5 (Confidence: 21.19%) | Safebet: 4\n",
      "Jakob Poeltl (REB) - 4 to 7 (Confidence: 60.31%) | Safebet: 5\n",
      "Jamal Shead (REB) - 0 to 1 (Confidence: 27.11%) | Safebet: 1\n",
      "Andre Drummond (REB) - 1 to 5 (Confidence: 39.75%) | Safebet: 2\n",
      "Guerschon Yabusele (AST) - 0 to 2 (Confidence: 25.65%) | Safebet: 2\n",
      "Justin Edwards (3PM) - 0 to 1 (Confidence: 33.97%) | Safebet: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df = df_merged\n",
    "\n",
    "# Function to create parlays\n",
    "def create_parlays(df):\n",
    "    parlays = {\"Balanced & High Confidence\": [], \"More Risk, Higher Payout\": [], \"Safe & Consistent Play\": []}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        player = row[\"Player\"]\n",
    "        \n",
    "        # Collect the stats and confidence levels in separate categories\n",
    "        stats = {\n",
    "            \"REB\": (row[\"REB\"], row[\"confidence_level_REB\"], row[\"safebet_REB\"]),\n",
    "            \"AST\": (row[\"AST\"], row[\"confidence_level_AST\"], row[\"safebet_AST\"] ),\n",
    "            \"PTS\": (row[\"PTS\"], row[\"confidence_level_PTS\"],row[\"safebet_PTS\"] ),\n",
    "            \"3PM\": (row[\"3PM\"], row[\"confidence_level_3PM\"],row[\"safebet_3PM\"] ),\n",
    "        }\n",
    "        \n",
    "        # Sort stats by confidence level (highest first)\n",
    "        sorted_stats = sorted(stats.items(), key=lambda x: x[1][1], reverse=True)\n",
    "        \n",
    "        # Add players to parlays\n",
    "        parlays[\"Balanced & High Confidence\"].append((player, sorted_stats[0][0], sorted_stats[0][1][0], sorted_stats[0][1][1], sorted_stats[0][1][2]))\n",
    "        parlays[\"More Risk, Higher Payout\"].append((player, sorted_stats[1][0], sorted_stats[1][1][0], sorted_stats[1][1][1], sorted_stats[1][1][2]))\n",
    "        parlays[\"Safe & Consistent Play\"].append((player, sorted_stats[2][0], sorted_stats[2][1][0], sorted_stats[2][1][1], sorted_stats[2][1][2]))\n",
    "\n",
    "    return parlays\n",
    "\n",
    "# Function to print parlays\n",
    "def print_parlays(parlays):\n",
    "    for parlay_name, parlay_list in parlays.items():\n",
    "        print(f\"{parlay_name}:\")\n",
    "        for player, stat, value, confidence, safebet in parlay_list:\n",
    "            print(f\"{player} ({stat}) - {value} (Confidence: {confidence}%) | Safebet: {safebet}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Create parlays\n",
    "parlays = create_parlays(df)\n",
    "\n",
    "# Print the parlays\n",
    "print_parlays(parlays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_function import fga_prediction\n",
    "\n",
    "\n",
    "SAS = {'Chris Paul': 'SAS',\"De'Aaron Fox\": 'SAS', \"Devin Vassell\": 'SAS',\"Harrison Barnes\": 'SAS'}\n",
    "OKC = { 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC', 'Shai Gilgeous-Alexander':'OKC'}\n",
    "\n",
    "player_names = SAS\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "results = fga_prediction(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path)\n",
    "\n",
    "\n",
    "for player, fga_predictions in results.items():\n",
    "    print(fga_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_path(base_path, **Kwargs):\n",
    "    # Replace placeholders with actual values\n",
    "    for key, value in Kwargs.items():\n",
    "        base_path=base_path.replace(f\"{{{key}}}\", str(value))\n",
    "    return base_path\n",
    "\n",
    "base_path = \"/data/{year}/{month}/{day}/file.txt\"\n",
    "kwargs = {'year': 2025, 'month': '02', 'day': '10'}\n",
    "year = 2025\n",
    "build_data_path(base_path, year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "schedule_df = pd.read_csv(\"D:/nba_scheduled_csv/schedule_csv_2025/OKC_schedule_content.csv\")\n",
    "\n",
    "schedule_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fga_prediction(player_names: dict, date_list: list, usage_path, player_base_path, defense_base_path, schedule_base_path):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list,usage_path,player_base_path, defense_base_path)\n",
    "\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # print(schedule_df)\n",
    "\n",
    "    for player, df in fga_prediction_data.items():\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "        features = ['PACE', 'team_pace', 'USG', 'DefRtg','MIN_x', 'home_away', 'Date_in_Seconds','OffRtg', 'team_offrtg']\n",
    "        target = 'FGA'\n",
    "\n",
    "\n",
    "        # Continue with your existing operations\n",
    "        timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "        test_data =  df[df['Date_in_Seconds'] >= timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "\n",
    "\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[target]\n",
    "        X_test = test_data[features]\n",
    "        y_test = test_data[target]\n",
    "\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        ###### predicting Minutes ##########\n",
    "        alpha = 0.2\n",
    "\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "\n",
    "        last_actual = df['MIN_x'].iloc[-1]  # Last known FGA\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]  # Last smoothed value\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = next_value.round(2)\n",
    "\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1] \n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, ['TEAM','PACE', 'DefRtg', 'OffRtg']]\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "        # print(first_team)\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "        # print(schedule_team_result)\n",
    "\n",
    "        schedule_defrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'DefRtg'].values[0]\n",
    "\n",
    "        schedule_pace = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'PACE'].values[0]\n",
    "\n",
    "        schedule_offrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'OffRtg'].values[0]\n",
    "\n",
    "        # print(\"dfrtg:\",schedule_defrtg)\n",
    "        # print(\"pace\",schedule_pace)\n",
    "        # print(\"offrtg\",schedule_offrtg)\n",
    "\n",
    "        # This is to turn the first date in schedule into seconds\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "\n",
    "        # This is to turn the home and away games into a 1 or a zero -> away is 1 and anything is zero\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # display(schedule_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X_future = pd.DataFrame({\n",
    "        # 'EWMA_FGA_2': [next_value], \n",
    "        'PACE':[schedule_pace], \n",
    "        'team_pace':[df['team_pace'].iloc[-1]], \n",
    "        'USG':[df['USG'].iloc[-1]],\n",
    "        'DefRtg':[schedule_defrtg],\n",
    "        'MIN_x':[next_value], \n",
    "        'home_away':[schedule_df['home_away'].iloc[0]],\n",
    "        'Date_in_Seconds':[schedule_df['Date_in_Seconds'].iloc[0]],\n",
    "        'OffRtg':[df['OffRtg'].iloc[-1]],\n",
    "        'team_offrtg': [schedule_offrtg]\n",
    "        })\n",
    "\n",
    "        display(X_future)\n",
    "\n",
    "        future_predictions = model.predict(X_future)\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"this is future\",future_predictions)\n",
    "\n",
    "        fga_prediction_results.update({player:future_predictions[0]})\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return fga_prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_player_defense_data, current_player_defense_data, build_data_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def his_usage_team(player_names: dict, date_list: list, usage_path,player_base_path,defense_base_path):\n",
    "    current_player_dic = {}\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        current_player_frames =[]\n",
    "\n",
    "        for date in date_list:\n",
    "            usage_path =build_data_path(usage_path,date=date)\n",
    "            usage_data = pd.read_csv(usage_path)\n",
    "\n",
    "            #merging player and defense dat into one\n",
    "            merged_data, current_defense_df = his_player_defense_data(player_base_path,defense_base_path,player,date)\n",
    "\n",
    "            #adding season to usage_data\n",
    "            usage_data['season'] = date\n",
    "\n",
    "            #Getting the player usage percentage for usage data and adding to merge\n",
    "            player_usage = usage_data.loc[usage_data['Player'] == player, 'USG%'].values[0]\n",
    "            merged_data['USG'] = player_usage\n",
    "\n",
    "            #adding the current player team pace\n",
    "            team_stat = current_defense_df.loc[current_defense_df['TEAM'] == team, 'PACE'].values[0]\n",
    "            merged_data[\"team_pace\"] = team_stat\n",
    "\n",
    "            # adding current player team OffRtg\n",
    "            team_offrtg = current_defense_df.loc[current_defense_df['TEAM'] == team, 'OffRtg'].values[0]\n",
    "            merged_data[\"team_offrtg\"] = team_offrtg\n",
    "\n",
    "            team_poss = current_defense_df.loc[current_defense_df['TEAM'] == team, 'POSS'].values[0]\n",
    "            merged_data[\"team_poss\"] = team_poss\n",
    "            \n",
    "            # Exclude rows where the TEAM column matches the given team\n",
    "            merged_data = merged_data[merged_data['TEAM'] != team]\n",
    "\n",
    "\n",
    "            # merged_data = merged_data[['season','Date', 'Home/Away_game' ,'Matchup' ,'PTS','MIN_x', 'Team', 'TEAM', 'FGA', 'USG', 'DefRtg', 'PACE','team_pace']]\n",
    "\n",
    "            # Turn date into seconds\n",
    "            merged_data['Date_in_Seconds'] = pd.to_datetime(merged_data['Date']).astype('int64') // 10**9\n",
    "            merged_data = merged_data.sort_values(by=\"Date_in_Seconds\")\n",
    "\n",
    "\n",
    "            # Turn Home/Away game into 1 and 0\n",
    "            merged_data['home_away'] = merged_data['Home/Away_game'].apply(lambda x: 1 if x == 'Away' else 0)\n",
    "            # Dropping duplicates\n",
    "            merged_data = merged_data.drop_duplicates()\n",
    "            \n",
    "            # Append the DataFrame for this date to the player's list\n",
    "            current_player_frames.append(merged_data)\n",
    "\n",
    "        # Combine all dates for the current player into one DataFrame\n",
    "        current_player_dic[player] = pd.concat(current_player_frames, ignore_index=True)\n",
    "\n",
    "\n",
    "    return current_player_dic, current_defense_df\n",
    "\n",
    "\n",
    "player_names = { 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC', 'Shai Gilgeous-Alexander':'OKC'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "def fga_prediction(player_names: dict, date_list: list, usage_path, player_base_path, defense_base_path, schedule_base_path):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        # Get schedule data for the player's team\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # Get player-specific prediction data\n",
    "\n",
    "        df = fga_prediction_data[player]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Model training and prediction code\n",
    "        features = ['PACE', 'team_pace', 'USG', 'DefRtg', 'MIN_x', 'home_away', 'Date_in_Seconds', 'OffRtg', 'team_offrtg']\n",
    "        target = 'FGA'\n",
    "\n",
    "        timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]\n",
    "        test_data = df[df['Date_in_Seconds'] >= timestamp]\n",
    "\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[target]\n",
    "        X_test = test_data[features]\n",
    "        y_test = test_data[target]\n",
    "\n",
    "        # Initialize Scaler\n",
    "        scaler = StandardScaler()\n",
    "        # Transform Data\n",
    "        scaled_data_x = scaler.fit_transform(X_train)\n",
    "        scaled_data_y = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "        X_train = pd.DataFrame(scaled_data_x, columns=X_train.columns)     \n",
    "        y_train = pd.DataFrame(scaled_data_y, columns=['features'])   \n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f\"{player}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        # EWMA calculation for minutes\n",
    "        alpha = 0.2\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "        last_actual = df['MIN_x'].iloc[-1]\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = round(next_value, 2)\n",
    "\n",
    "        # Get defensive stats for the scheduled team\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1]\n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, ['TEAM', 'PACE', 'DefRtg', 'OffRtg']]\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "        schedule_defrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'DefRtg'].values[0]\n",
    "        schedule_pace = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'PACE'].values[0]\n",
    "        schedule_offrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'OffRtg'].values[0]\n",
    "\n",
    "        # Convert schedule dates to seconds\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "        # Create future prediction dataframe\n",
    "        X_future = pd.DataFrame({\n",
    "            'PACE': [schedule_pace],\n",
    "            'team_pace': [df['team_pace'].iloc[-1]],\n",
    "            'USG': [df['USG'].iloc[-1]],\n",
    "            'DefRtg': [schedule_defrtg],\n",
    "            'MIN_x': [next_value],\n",
    "            'home_away': [schedule_df['home_away'].iloc[0]],\n",
    "            'Date_in_Seconds': [schedule_df['Date_in_Seconds'].iloc[0]],\n",
    "            'OffRtg': [df['OffRtg'].iloc[-1]],\n",
    "            'team_offrtg': [schedule_offrtg]\n",
    "        })\n",
    "\n",
    "        future_predictions = model.predict(X_future)\n",
    "        fga_prediction_results[player] = future_predictions[0]\n",
    "\n",
    "    return fga_prediction_results\n",
    "\n",
    "results = fga_prediction(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path)\n",
    "\n",
    "\n",
    "for player, fga_predictions in results.items():\n",
    "    print(fga_predictions)\n",
    "   \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_functions as data_functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.invalidate_caches()\n",
    "from data_functions import his_player_defense_data, current_player_defense_data\n",
    "\n",
    "#\"D:\\nba_player_csv_current\\season_2024-25\\all_quarters\\Alex Caruso_content.csv\"\n",
    "#\"D:\\nba_defense_csv_current\\defense_csv_2024-25\\all_quarter_defense_content.csv\"\n",
    "#\"D:\\nba_scheduled_csv\\schedule_csv_2025\\ATL_schedule_content.csv\"\n",
    "\n",
    "player_names = {'Shai Gilgeous-Alexander':'OKC', 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "# usage_data = f\"D:/nba_usage_csv_current/usage_csv_{date}/{date}_content.csv\"\n",
    "\n",
    "\n",
    "\n",
    "current_player_dic = {}\n",
    "\n",
    "for player, team in player_names.items():\n",
    "  current_player_frames = []\n",
    "\n",
    "  for date in date_list:\n",
    "    usage_data = pd.read_csv(f\"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\")  \n",
    "\n",
    "    # use current_player function to to merge datat\n",
    "    merged_data, current_player_defense = his_player_defense_data(player_base_path,defense_base_path,player,date)\n",
    "\n",
    "    # Add the season column to usage_data\n",
    "    usage_data['season'] = date\n",
    "    \n",
    "    # Get the player's usage percentage from the usage data\n",
    "    # (Assumes that there is exactly one matching row)\n",
    "    player_usage = usage_data.loc[usage_data['Player'] == player, 'USG%'].values[0]\n",
    "    merged_data['USG'] = player_usage\n",
    "\n",
    "\n",
    "    # adding current player team pace\n",
    "    team_stat = current_player_defense.loc[current_player_defense['TEAM'] == team, 'PACE'].values[0]\n",
    "    merged_data[\"team_pace\"] = team_stat\n",
    "\n",
    "    # display(current_player_defense)\n",
    "\n",
    "    # adding current player team OffRtg\n",
    "    team_offrtg = current_player_defense.loc[current_player_defense['TEAM'] == team, 'OffRtg'].values[0]\n",
    "    merged_data[\"team_offrtg\"] = team_offrtg\n",
    "\n",
    "    team_poss = current_player_defense.loc[current_player_defense['TEAM']== team, 'POSS'].values[0]\n",
    "    merged_data[\"team_poss\"] = team_poss\n",
    "\n",
    "    # Exclude rows where the TEAM column matches the given team\n",
    "    merged_data = merged_data[merged_data['TEAM'] != team]\n",
    "    # display(merged_data.head(5))\n",
    "\n",
    "    # merged_data = merged_data[['season','Date', 'Home/Away_game' ,'Matchup' ,'PTS','MIN_x', 'Team', 'TEAM', 'FGA', 'USG', 'DefRtg', 'PACE','team_pace']]\n",
    "\n",
    "    # Turn date into seconds\n",
    "    merged_data['Date_in_Seconds'] = pd.to_datetime(merged_data['Date']).astype('int64') // 10**9\n",
    "    merged_data = merged_data.sort_values(by=\"Date_in_Seconds\")\n",
    "\n",
    "    # Turn Home/Away game into 1 and 0\n",
    "    merged_data['home_away'] = merged_data['Home/Away_game'].apply(lambda x: 1 if x == 'Away' else 0)\n",
    "    # Dropping duplicates\n",
    "    merged_data = merged_data.drop_duplicates()\n",
    "    \n",
    "    # Append the DataFrame for this date to the player's list\n",
    "    current_player_frames.append(merged_data)\n",
    "\n",
    "  # Combine all dates for the current player into one DataFrame\n",
    "  current_player_dic[player] = pd.concat(current_player_frames, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "specific_player = 'Shai Gilgeous-Alexander'\n",
    "for player, df in current_player_dic.items():\n",
    "\n",
    "    print(f\"\\nData for {player}:\")\n",
    "    df['FGA_rolling_3'] = df['FGA'].rolling(window=3).mean()\n",
    "\n",
    "\n",
    "\n",
    "    alpha = 0.2\n",
    "\n",
    "    df['EWMA_FGA'] = df['FGA'].ewm(span=(2/(1-alpha)-1), adjust=False).mean()\n",
    "\n",
    "    df['EWMA_FGA_2'] = df['FGA'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "\n",
    "    # alpha = 0.2  # Example smoothing factor\n",
    "    df['Exp_smooth'] = 21  # Initialize column\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        df.loc[i, 'Exp_smooth'] = alpha * df.loc[i, 'FGA'] + (1 - alpha) * df.loc[i - 1, 'Exp_smooth']\n",
    "\n",
    "    df_act = df\n",
    "\n",
    "    # display(df_act)\n",
    "\n",
    "    # display(df)\n",
    "    df = df.head(149)\n",
    "\n",
    "    value_fga_list = []\n",
    "    moving_average_list = []\n",
    "    next_next_value_list = []\n",
    "    date_list = []\n",
    "    \n",
    "    for value_fga, moving_average, date in zip(df['FGA'],df['EWMA_FGA_2'],df['Date']):\n",
    "       value_fga_list.append(value_fga)\n",
    "       moving_average_list.append(moving_average)\n",
    "       #print(\"this is actual:\",value_fga, \"this is last_predicted\",moving_average)\n",
    "       next_next_value = alpha * value_fga + (1 - alpha) * moving_average\n",
    "       next_next_value_list.append(next_next_value)\n",
    "       date_list.append(date)\n",
    "       #print(\"this is next:\",next_next_value)\n",
    "       dataframe_dic= {'Date':date_list,'Actual_FGA': value_fga_list, 'Moving_average':moving_average_list, 'Next':next_next_value_list}\n",
    "       dataframe = pd.DataFrame(dataframe_dic)\n",
    "      #  dataframe['Next'] = dataframe['Next'].shift(1)\n",
    "\n",
    "    # display(dataframe)\n",
    "\n",
    "\n",
    "    # Predict the next (11th) value\n",
    "    last_actual = df['FGA'].iloc[-1]  # Last known FGA\n",
    "    last_smoothed = df['EWMA_FGA_2'].iloc[-1]  # Last smoothed value\n",
    "    next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "\n",
    "\n",
    "    # Print and add the prediction\n",
    "    print(f\"Predicted value: {next_value}\")\n",
    "\n",
    "    # display(df)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "    features = ['PACE', 'team_pace', 'USG', 'DefRtg','MIN_x', 'home_away', 'Date_in_Seconds','OffRtg', 'team_offrtg']\n",
    "    target = 'FGA'\n",
    "\n",
    "\n",
    "     # Continue with your existing operations\n",
    "    timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "    train_data = df[df['Date_in_Seconds'] < timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "    test_data =  df[df['Date_in_Seconds'] >= timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[target]\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # print(y_pred)\n",
    "\n",
    "     # Compare predictions with actual points\n",
    "    predicted_vs_actual = pd.DataFrame({\n",
    "        \"Date\": test_data['Date'],  \n",
    "        \"Matchup\": test_data['Matchup'],  \n",
    "        \"Predicted Points\": y_pred.round(1), \n",
    "        \"Actual Points\": y_test}).reset_index(drop=True)\n",
    "    \n",
    "    display(predicted_vs_actual)\n",
    "\n",
    "    X_future = pd.DataFrame({\n",
    "    # 'EWMA_FGA_2': [next_value], \n",
    "    'PACE':[df['PACE'].iloc[-1]], \n",
    "    'team_pace':[df['team_pace'].iloc[-1]], \n",
    "    'USG':[df['USG'].iloc[-1]],\n",
    "    'DefRtg':[df['DefRtg'].iloc[-1]],\n",
    "    'MIN_x':[30.09], \n",
    "    'home_away':[1],\n",
    "    'Date_in_Seconds':[1738368000],\n",
    "    'OffRtg':[df['OffRtg'].iloc[-1]],\n",
    "    'team_offrtg': [df['team_offrtg'].iloc[-1]]\n",
    "    })\n",
    "    \n",
    "    future_predictions = model.predict(X_future)\n",
    "\n",
    "    print(\"this is future\",future_predictions)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Drop NaN values (first row of 'Next' is NaN due to shift)\n",
    "    rmse_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(((rmse_df['Actual_FGA'] - rmse_df['Next']) ** 2).mean())\n",
    "\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "\n",
    "    # Drop NaN values (due to shift)\n",
    "    comparison_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Total number of valid comparisons\n",
    "    total = len(comparison_df)\n",
    "\n",
    "    # Count occurrences\n",
    "    higher_count = (comparison_df['Next'] > comparison_df['Actual_FGA']).sum()\n",
    "    lower_count = (comparison_df['Next'] < comparison_df['Actual_FGA']).sum()\n",
    "    equal_count = (comparison_df['Next'] == comparison_df['Actual_FGA']).sum()\n",
    "\n",
    "    # Calculate percentages\n",
    "    higher_percent = (higher_count / total) * 100\n",
    "    lower_percent = (lower_count / total) * 100\n",
    "    equal_percent = (equal_count / total) * 100\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Percentage of predictions HIGHER than actual: {higher_percent:.2f}%\")\n",
    "    print(f\"Percentage of predictions LOWER than actual: {lower_percent:.2f}%\")\n",
    "    print(f\"Percentage of predictions EQUAL to actual: {equal_percent:.2f}%\")\n",
    "\n",
    "\n",
    "    comparison_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Filter cases where Next is higher than Actual\n",
    "    higher_cases = comparison_df[comparison_df['Next'] > comparison_df['Actual_FGA']]\n",
    "    higher_difference_avg = (higher_cases['Next'] - higher_cases['Actual_FGA']).mean()\n",
    "\n",
    "    # Filter cases where Next is lower than Actual\n",
    "    lower_cases = comparison_df[comparison_df['Next'] < comparison_df['Actual_FGA']]\n",
    "    lower_difference_avg = (lower_cases['Actual_FGA'] - lower_cases['Next']).mean()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average difference when prediction is HIGHER: {higher_difference_avg:.2f}\")\n",
    "    print(f\"Average difference when prediction is LOWER: {lower_difference_avg:.2f}\")\n",
    "\n",
    "    # Drop NaN values\n",
    "    comparison_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Compute Mean Error (ME)\n",
    "    mean_error = (comparison_df['Next'] - comparison_df['Actual_FGA']).mean()\n",
    "\n",
    "    # Print result\n",
    "    print(f\"Mean Error (ME): {mean_error:.2f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
