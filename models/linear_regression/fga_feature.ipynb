{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_usage_team\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def select_features(player_names, date_list, usage_path, player_base_path, defense_base_path):\n",
    "    player_df, _ = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    \n",
    "    selected_features_dict = {}\n",
    "    \n",
    "    for player, df in player_df.items():\n",
    "        df_X = df.drop(columns=['PTS','Date','Matchup','Team','Home/Away_game','W/L', 'Away', 'season', 'TEAM', 'season_defense'])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(df_X)\n",
    "        y = df['PTS']  # Target variable\n",
    "        \n",
    "        # Grid search parameters for Lasso\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "        grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best alpha and fit Lasso\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_lasso = Lasso(alpha=best_alpha)\n",
    "        best_lasso.fit(X, y)\n",
    "        \n",
    "        # Select non-zero coefficient features\n",
    "        X = pd.DataFrame(X, columns=df_X.columns)\n",
    "        selected_features = X.columns[best_lasso.coef_ != 0].tolist()\n",
    "        selected_features_dict[player] = selected_features\n",
    "        \n",
    "    return selected_features_dict\n",
    "\n",
    "\n",
    "player_names = {\n",
    "    \"Jayson Tatum\": \"BOS\",\n",
    "    # \"Nikola Jokic\": \"DEN\",\n",
    "    \"Jamal Murray\": \"DEN\",\n",
    "    \"Jaylen Brown\": \"BOS\",\n",
    "    \"Derrick White\": \"BOS\",\n",
    "    \"Payton Pritchard\": \"BOS\",\n",
    "    \"Michael Porter Jr.\": \"DEN\",\n",
    "    \"Russell Westbrook\": \"DEN\",\n",
    "    \"Christian Braun\": \"DEN\",\n",
    "    \"Al Horford\": \"BOS\",\n",
    "    # \"Julian Strawther\": \"DEN\",\n",
    "    \"Sam Hauser\": \"BOS\",\n",
    "    \"Zeke Nnaji\": \"DEN\",\n",
    "    \"Luke Kornet\": \"BOS\"\n",
    "}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "select_features(player_names, date_list, usage_path, player_base_path, defense_base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_usage_team\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "{ 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC', 'Shai Gilgeous-Alexander':'OKC'}\n",
    "{'Chris Paul': 'SAS',\"De'Aaron Fox\": 'SAS', \"Devin Vassell\": 'SAS',\"Harrison Barnes\": 'SAS'}\n",
    "\n",
    "player_names = {\"Payton Pritchard\": 'BOS'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "player_df, current_defense_stat = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "\n",
    "\n",
    "\n",
    "for player, df in player_df.items():\n",
    "    print(player)\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import numpy as np\n",
    "\n",
    "    df_X = df.drop(columns=['PTS','Date','Matchup','Team','Home/Away_game','W/L', 'Away', 'season', 'TEAM', 'season_defense'])\n",
    "\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df_X)\n",
    "\n",
    "    y = df['PTS']  # Replace with your actual target\n",
    "\n",
    "\n",
    "    # Define the grid search parameters for Lasso (L1 regularization)\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10]  # Different levels of regularization strength\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print best parameters\n",
    "    print(\"Best alpha:\", grid_search.best_params_)\n",
    "\n",
    "    X = pd.DataFrame(X, columns=df_X.columns)  # Convert back to DataFrame\n",
    "\n",
    "\n",
    "    # Get the best alpha\n",
    "    best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "    # Fit Lasso with the best alpha\n",
    "    best_lasso = Lasso(alpha=best_alpha)\n",
    "    best_lasso.fit(X, y)\n",
    "\n",
    "\n",
    "    # Get selected (non-zero) feature indices\n",
    "    selected_features = X.columns[best_lasso.coef_ != 0]\n",
    "    print(\"Selected features:\", selected_features)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # display(y_test)\n",
    "\n",
    "    timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "    train_data = df[df['Date_in_Seconds'] < timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "    test_data =  df[df['Date_in_Seconds'] >= timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "\n",
    "    X_train = train_data[selected_features]\n",
    "    y_train = train_data['FGM']\n",
    "    X_test = test_data[selected_features]\n",
    "    y_test = test_data['FGM']\n",
    "\n",
    "\n",
    "\n",
    "    # Reduce X to selected features only\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "\n",
    "\n",
    "    # Retrain Lasso only on selected features\n",
    "    final_lasso = Lasso(alpha=best_alpha)\n",
    "    final_lasso.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predict on the test set using the reduced feature set\n",
    "    y_pred = final_lasso.predict(X_test_selected)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(\"Final RMSE using selected features:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+02, tolerance: 8.493e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e+01, tolerance: 8.418e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.727e+01, tolerance: 8.019e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.945e+01, tolerance: 8.078e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+02, tolerance: 8.000e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+00, tolerance: 8.078e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e+01, tolerance: 6.306e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.340e+01, tolerance: 6.280e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.935e+01, tolerance: 5.490e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.214e+01, tolerance: 6.388e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.396e+01, tolerance: 5.958e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e-02, tolerance: 5.490e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+02, tolerance: 7.227e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.711e+01, tolerance: 6.032e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+02, tolerance: 7.578e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+02, tolerance: 7.463e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+02, tolerance: 7.777e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e-01, tolerance: 7.227e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.049e-02, tolerance: 7.463e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.346e-01, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e-01, tolerance: 2.372e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.194e-01, tolerance: 2.132e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e-01, tolerance: 2.370e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.494e-02, tolerance: 1.555e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e+01, tolerance: 5.057e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.458e+01, tolerance: 4.851e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+01, tolerance: 4.746e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.917e+01, tolerance: 4.956e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.251e+00, tolerance: 4.558e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.543e+01, tolerance: 6.681e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.308e+01, tolerance: 5.664e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+00, tolerance: 6.191e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+00, tolerance: 5.611e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+01, tolerance: 6.020e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e-01, tolerance: 5.611e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+00, tolerance: 7.516e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.449e+00, tolerance: 7.006e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e+00, tolerance: 6.716e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.687e+00, tolerance: 8.512e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+00, tolerance: 8.628e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.096e+01, tolerance: 4.372e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.047e+01, tolerance: 4.394e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.170e+01, tolerance: 5.122e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.088e+01, tolerance: 5.163e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e+01, tolerance: 4.476e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.846e-02, tolerance: 5.122e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+01, tolerance: 2.336e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+01, tolerance: 2.499e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+01, tolerance: 2.459e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.861e-01, tolerance: 2.731e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.815e+01, tolerance: 2.392e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.364e-02, tolerance: 2.731e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.650e-01, tolerance: 1.125e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+00, tolerance: 1.001e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.531e-02, tolerance: 1.121e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e-01, tolerance: 9.921e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.012e-02, tolerance: 9.300e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+02, tolerance: 6.926e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+02, tolerance: 7.651e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+02, tolerance: 7.807e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+02, tolerance: 7.749e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+02, tolerance: 7.920e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e-01, tolerance: 7.651e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.300e-01, tolerance: 7.807e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e-01, tolerance: 7.920e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devin Booker : ['MIN_x', 'PTS', 'FG%', '3PM', 'FTM', 'FTA', 'STL', 'BLK', '+/-', 'MIN_y', 'DefRtg', 'AST%', 'ASTRatio', 'DREB%', 'REB%', 'Date_in_Seconds']\n",
      "Anthony Edwards : ['MIN_x', 'FG%', '3P%', 'FT%', 'DREB', 'STL', 'BLK', 'TOV', '+/-', 'L', 'DefRtg', 'AST%', 'OREB%', 'DREB%', 'REB%', 'TOV%', 'home_away']\n",
      "Kevin Durant : ['MIN_x', 'FG%', '3P%', 'FT%', 'DREB', 'STL', 'BLK', 'TOV', '+/-', 'L', 'DefRtg', 'AST%', 'OREB%', 'DREB%', 'REB%', 'TOV%', 'home_away']\n",
      "Naz Reid : ['MIN_x', '3PA', '3P%', 'DREB', 'REB', 'TOV', '+/-', 'GP', 'OffRtg', 'AST/TO']\n",
      "Julius Randle : ['MIN_x', 'FG%', '3P%', 'FT%', 'DREB', 'STL', 'BLK', 'TOV', '+/-', 'L', 'DefRtg', 'AST%', 'OREB%', 'DREB%', 'REB%', 'TOV%', 'home_away']\n",
      "Bradley Beal : ['MIN_x', 'PTS', 'FGM', 'FG%', 'OREB', 'STL', 'BLK', 'TOV', 'PF', '+/-', 'L', 'DefRtg', 'TOV%', 'PACE', 'POSS', 'home_away']\n",
      "Bol Bol : ['MIN_x', 'DREB', 'STL', '+/-', 'team_pace', 'Date_in_Seconds']\n",
      "Donte DiVincenzo : ['MIN_x', '3P%', 'FTA', 'DREB', 'STL', 'BLK', '+/-', 'DefRtg', 'OREB%', 'DREB%', 'TOV%', 'PACE', 'team_offrtg']\n",
      "Jaden McDaniels : ['MIN_x', 'FG%', '3P%', 'FT%', 'DREB', 'STL', 'BLK', 'TOV', '+/-', 'L', 'DefRtg', 'AST%', 'OREB%', 'DREB%', 'REB%', 'TOV%', 'home_away']\n",
      "Nick Richards : ['MIN_x', 'BLK', 'TOV', 'POSS']\n",
      "Mike Conley : ['MIN_x']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from data_functions import his_usage_team\n",
    "\n",
    "def select_features(player_names, date_list, usage_path, player_base_path, defense_base_path, target):\n",
    "    player_df, _ = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    \n",
    "    selected_features_dict = {}\n",
    "    \n",
    "    max_features_player = None\n",
    "    max_features = 0\n",
    "\n",
    "    for player, df in player_df.items():\n",
    "        df_X = df.drop(columns=[target,'Date','Matchup','Team','Home/Away_game','W/L', 'Away', 'season', 'TEAM', 'season_defense'])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(df_X)\n",
    "        y = df[target]  # Target variable\n",
    "        \n",
    "        # Grid search parameters for Lasso\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "        grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best alpha and fit Lasso\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_lasso = Lasso(alpha=best_alpha)\n",
    "        best_lasso.fit(X, y)\n",
    "        \n",
    "        # Select non-zero coefficient features\n",
    "        X = pd.DataFrame(X, columns=df_X.columns)\n",
    "        selected_features = X.columns[best_lasso.coef_ != 0].tolist()\n",
    "        \n",
    "        # Store selected features\n",
    "        selected_features_dict[player] = selected_features\n",
    "        \n",
    "        # Track the player with the most features\n",
    "        if len(selected_features) > max_features:\n",
    "            max_features = len(selected_features)\n",
    "            max_features_player = player\n",
    "\n",
    "    # If a player has no selected features, assign the features of the player with the most features\n",
    "    for player in selected_features_dict:\n",
    "        if not selected_features_dict[player]:  # If empty\n",
    "            selected_features_dict[player] = selected_features_dict.get(max_features_player, [])\n",
    "\n",
    "    return selected_features_dict\n",
    "\n",
    "\n",
    "player_names = {\n",
    "    \"Devin Booker\": \"PHX\",\n",
    "    \"Anthony Edwards\": \"MIN\",\n",
    "    \"Kevin Durant\": \"PHX\",\n",
    "    \"Naz Reid\": \"MIN\",\n",
    "    \"Julius Randle\": \"MIN\",\n",
    "    \"Bradley Beal\": \"PHX\",\n",
    "    \"Bol Bol\": \"PHX\",\n",
    "    \"Donte DiVincenzo\": \"MIN\",\n",
    "    \"Jaden McDaniels\": \"MIN\",\n",
    "    \"Nick Richards\": \"PHX\",\n",
    "    \"Mike Conley\": \"MIN\"\n",
    "}\n",
    "\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "feature_dic = select_features(player_names, date_list, usage_path, player_base_path, defense_base_path,'AST')\n",
    "\n",
    "for player, features in feature_dic.items():\n",
    "    # print(player)\n",
    "    features = feature_dic[player] \n",
    "    print(player,':',features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_usage_team\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def select_features(player_names, date_list, usage_path, player_base_path, defense_base_path, target):\n",
    "    player_df, _ = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    \n",
    "    selected_features_dict = {}\n",
    "    \n",
    "    for player, df in player_df.items():\n",
    "        df_X = df.drop(columns=[target,'Date','Matchup','Team','Home/Away_game','W/L', 'Away', 'season', 'TEAM', 'season_defense'])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(df_X)\n",
    "        y = df[target]  # Target variable\n",
    "        \n",
    "        # Grid search parameters for Lasso\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "        grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best alpha and fit Lasso\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_lasso = Lasso(alpha=best_alpha)\n",
    "        best_lasso.fit(X, y)\n",
    "        \n",
    "        # Select non-zero coefficient features\n",
    "        X = pd.DataFrame(X, columns=df_X.columns)\n",
    "        selected_features = X.columns[best_lasso.coef_ != 0].tolist()\n",
    "        selected_features_dict[player] = selected_features\n",
    "        \n",
    "    return selected_features_dict\n",
    "\n",
    "\n",
    "player_names = {\n",
    "    \"Devin Booker\": \"PHX\",\n",
    "    \"Anthony Edwards\": \"MIN\",\n",
    "    \"Kevin Durant\": \"PHX\",\n",
    "    \"Naz Reid\": \"MIN\",\n",
    "    \"Julius Randle\": \"MIN\",\n",
    "    \"Bradley Beal\": \"PHX\",\n",
    "    \"Bol Bol\": \"PHX\",\n",
    "    \"Donte DiVincenzo\": \"MIN\",\n",
    "    \"Jaden McDaniels\": \"MIN\",\n",
    "    \"Nick Richards\": \"PHX\",\n",
    "    \"Mike Conley\": \"MIN\"\n",
    "}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "feature_dic = select_features(player_names, date_list, usage_path, player_base_path, defense_base_path,'AST')\n",
    "\n",
    "for player, features in feature_dic.items():\n",
    "    # print(player)\n",
    "    features = feature_dic[player] \n",
    "    print(player,':',features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for shai\n",
    "# 'MIN_x', 'FGM', 'FG%', '3PA', 'OREB', 'REB', 'RANK'\n",
    "\n",
    "from feature_function import his_usage_team, select_features\n",
    "from data_functions import his_player_defense_data, current_player_defense_data, build_data_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# player_names = {\"Payton Pritchard\": 'BOS'}\n",
    "\n",
    "player_names = {\n",
    "    \"Mark Williams\": \"CHA\",\n",
    "    # \"Miles Bridges\": \"CHA\",\n",
    "    # \"Jimmy Butler\": \"GSW\",\n",
    "    \"LaMelo Ball\": \"CHA\",\n",
    "    \"Stephen Curry\": \"GSW\",\n",
    "    # \"Brandin Podziemski\": \"GSW\",\n",
    "    # \"Nick Smith Jr.\": \"CHA\",\n",
    "    \"Josh Green\": \"CHA\",\n",
    "    \"Moses Moody\": \"GSW\",\n",
    "    \"Draymond Green\": \"GSW\",\n",
    "    \"Paul George\": \"PHI\",\n",
    "    \"Tyrese Maxey\": \"PHI\",\n",
    "    \"Kelly Oubre Jr.\": \"PHI\",\n",
    "    \"Andre Drummond\": \"PHI\",\n",
    "    \"Shaedon Sharpe\": \"POR\",\n",
    "    \"Quentin Grimes\": \"PHI\",\n",
    "    \"Deni Avdija\": \"POR\",\n",
    "    \"Anfernee Simons\": \"POR\",\n",
    "    # \"Toumani Camara\": \"POR\",\n",
    "    # \"Donovan Clingan\": \"POR\",\n",
    "    \"Bam Adebayo\": \"MIA\",\n",
    "    \"Tyler Herro\": \"MIA\",\n",
    "    \"Andrew Wiggins\": \"MIA\",\n",
    "    # \"Bilal Coulibaly\": \"WAS\",\n",
    "    # \"Alexandre Sarr\": \"WAS\",\n",
    "    \"Khris Middleton\": \"WAS\",\n",
    "    # \"Carlton Carrington\": \"WAS\",\n",
    "    \"Davion Mitchell\": \"MIA\",\n",
    "    # \"Kyshawn George\": \"WAS\",\n",
    "    \"Haywood Highsmith\": \"MIA\"\n",
    "}\n",
    "\n",
    "\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "def prediction(player_names: dict, date_list: list, usage_path, player_base_path, defense_base_path, schedule_base_path,selected_feature_target, prediction_target):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import pandas\n",
    "\n",
    "    # this is the function that will be used to select the features for the model prints out the player and the best features to use\n",
    "    feature_dic = select_features(player_names, date_list, usage_path, player_base_path, defense_base_path,selected_feature_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        # Get schedule data for the player's team\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # Get player-specific prediction data\n",
    "\n",
    "        df = fga_prediction_data[player]\n",
    "        \n",
    "\n",
    "\n",
    "        features = feature_dic[player] \n",
    "        # print(features)\n",
    "        target = prediction_target\n",
    "\n",
    "        timestamp = int(pd.Timestamp('2025-02-').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]\n",
    "        test_data = df[df['Date_in_Seconds'] >= timestamp]\n",
    "\n",
    "        display(test_data\n",
    "\n",
    "        X_train = train_data[features].fillna(0)\n",
    "        y_train = train_data[target].fillna(0)\n",
    "        X_test = test_data[features].fillna(0)\n",
    "        y_test = test_data[target].fillna(0) \n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f\"{player}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        # EWMA calculation for minutes\n",
    "        alpha = 0.2\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "        last_actual = df['MIN_x'].iloc[-1]\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = round(next_value, 2)\n",
    "\n",
    "\n",
    "        # Exclude columns\n",
    "        exclude_features = ['RANK', 'OffRtg', 'W', 'L', \n",
    "            'DefRtg','NetRtg', 'AST%', 'AST/TO', 'ASTRatio',\n",
    "            'OREB%', 'DREB%', 'REB%', 'TOV%' , 'eFG%', 'TS%', 'PACE',\n",
    "            'POSS', 'TEAM', 'PIE']\n",
    "        \n",
    "        exclude_features_schedule = ['home_away', 'schedule_team', 'DATE', 'location', 'season_defense']\n",
    "\n",
    "        # Get defensive stats for the scheduled team\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "        # df_defense = df_defense.merge(schedule_df, left_on='TEAM', right_on = 'schedule_team', how='outer', suffixes=('', '_DROP'))\n",
    "        # df_defense = df_defense.drop(columns=[col for col in df_defense.columns if col.endswith('_DROP')])\n",
    "        # df_defense= df_defense.fillna(0)\n",
    "\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1]\n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, exclude_features]\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "\n",
    "\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "\n",
    "\n",
    "        schedule_values = {feature: df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, feature].values[0] \n",
    "                for feature in exclude_features if feature in df_for_schedule.columns}\n",
    "\n",
    "        print(schedule_values)\n",
    "\n",
    "\n",
    "        # checking to see if the schedule values are being passed correctly\n",
    "        \n",
    "        rolling_features = [col for col in features  if col not in exclude_features]\n",
    "        # display(rolling_features)\n",
    "\n",
    "        # df = df[df['Date_in_Seconds'] >= timestamp]\n",
    "        # # display(df)\n",
    "\n",
    "        for col in rolling_features:\n",
    "            df[f'{col}'] = df[col].rolling(window=20).mean().fillna(0).astype(int)\n",
    "\n",
    "        df_last_rolling = df.iloc[[-1]][[f'{col}' for col in rolling_features]]\n",
    "\n",
    "        df_last_rolling = df_last_rolling.reset_index(drop=True)\n",
    "\n",
    "        for value in features:\n",
    "            if value in exclude_features:\n",
    "                print(f'This is the value {value}')\n",
    "                df_last_rolling[value] = schedule_values.get(value)\n",
    "                # df_last_rolling[value] = schedule_df[value].iloc[0]\n",
    "\n",
    "        for value in features:\n",
    "            if value in exclude_features_schedule:\n",
    "                print(f'This is the value {value}')\n",
    "                # df_last_rolling[value] = schedule_values.get(value)\n",
    "                df_last_rolling[value] = schedule_df[value].iloc[0]        \n",
    "\n",
    "\n",
    "\n",
    "        df_last_rolling = df_last_rolling.reindex(columns=features)\n",
    "\n",
    "        X_future = df_last_rolling\n",
    "\n",
    "        display(X_future)\n",
    "\n",
    "        future_predictions = model.predict(X_future).astype('int')\n",
    "        fga_prediction_results[player] = [future_predictions[0].round(1), rmse]\n",
    "        df_results = pd.DataFrame.from_dict(fga_prediction_results, orient='index', columns=[target, 'RMSE'])\n",
    "        # Reset index and rename it properly\n",
    "        df_results.reset_index(inplace=True)\n",
    "        df_results.rename(columns={'index': 'Player'}, inplace=True)\n",
    "        # display(df_results)\n",
    "\n",
    "\n",
    "    return   df_results\n",
    "\n",
    "results = prediction(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path,'PTS','PTS')\n",
    "\n",
    "\n",
    "# for player, fga_predictions in results.items():\n",
    "#     print(fga_predictions)\n",
    "\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 155\u001b[0m\n\u001b[0;32m    151\u001b[0m         fga_prediction_results[player] \u001b[38;5;241m=\u001b[39m player , future_predictions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fga_prediction_results\n\u001b[1;32m--> 155\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfga_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_base_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefense_base_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule_base_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m player, fga_predictions \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mprint\u001b[39m(fga_predictions)\n",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m, in \u001b[0;36mfga_prediction\u001b[1;34m(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Get player-specific prediction data\u001b[39;00m\n\u001b[0;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m fga_prediction_data[player]\n\u001b[1;32m---> 46\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mselected_features\u001b[49m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(features)\n\u001b[0;32m     48\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFGA\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selected_features' is not defined"
     ]
    }
   ],
   "source": [
    "# features for shai\n",
    "# 'MIN_x', 'FGM', 'FG%', '3PA', 'OREB', 'REB', 'RANK'\n",
    "\n",
    "from feature_function import his_usage_team\n",
    "from data_functions import his_player_defense_data, current_player_defense_data, build_data_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "player_names ={\"Jaylen Brown\": 'BOS'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "def fga_prediction(player_names: dict, date_list: list, usage_path, player_base_path, defense_base_path, schedule_base_path):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import pandas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        # Get schedule data for the player's team\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # Get player-specific prediction data\n",
    "\n",
    "        df = fga_prediction_data[player]\n",
    "\n",
    "\n",
    "        features = selected_features \n",
    "        print(features)\n",
    "        target = 'FGA'\n",
    "\n",
    "        timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]\n",
    "        test_data = df[df['Date_in_Seconds'] >= timestamp]\n",
    "\n",
    "        display(test_data)\n",
    "\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[target]\n",
    "        X_test = test_data[features]\n",
    "        y_test = test_data[target]\n",
    "\n",
    "        # # Initialize Scaler\n",
    "        # scaler = StandardScaler()\n",
    "        # # Transform Data\n",
    "        # scaled_data_x = scaler.fit_transform(X_train)\n",
    "        # scaled_data_y = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "        # X_train = pd.DataFrame(scaled_data_x, columns=X_train.columns)     \n",
    "        # y_train = pd.DataFrame(scaled_data_y, columns=['features'])   \n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f\"{player}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        # EWMA calculation for minutes\n",
    "        alpha = 0.2\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "        last_actual = df['MIN_x'].iloc[-1]\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = round(next_value, 2)\n",
    "\n",
    "\n",
    "        # Exclude columns\n",
    "        exclude_features = ['RANK', 'OffRtg', 'W', 'L', \n",
    "            'DefRtg','NetRtg', 'AST%', 'AST/TO', 'ASTRatio',\n",
    "            'OREB%', 'DREB%', 'REB%', 'TOV%' , 'eFG%', 'TS%', 'PACE',\n",
    "            'POSS', 'TEAM', 'home_away', 'PIE']\n",
    "\n",
    "        # Get defensive stats for the scheduled team\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "        df_defense = df_defense.merge(schedule_df, left_on='TEAM', right_on = 'schedule_team', how='outer')\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1]\n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, exclude_features]\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "        # could refactor to use squeeze but simpler to read this way\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "\n",
    "\n",
    "        schedule_values = {feature: df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, feature].values[0] \n",
    "                   for feature in exclude_features if feature in df_for_schedule.columns}\n",
    "\n",
    "        print(schedule_values)\n",
    "\n",
    "\n",
    "        # checking to see if \n",
    "        \n",
    "        rolling_features = [col for col in selected_features  if col not in exclude_features]\n",
    "\n",
    "        for col in rolling_features:\n",
    "            df[f'{col}'] = df[col].rolling(window=10).mean()\n",
    "\n",
    "        df_last_rolling = df.iloc[[-1]][[f'{col}' for col in rolling_features]]\n",
    "\n",
    "        df_last_rolling = df_last_rolling.reset_index(drop=True)\n",
    "\n",
    "        for value in selected_features:\n",
    "            if value in exclude_features:\n",
    "                print(f'This is the value {value}')\n",
    "                df_last_rolling[value] = schedule_values.get(value)\n",
    "\n",
    "\n",
    "\n",
    "        df_last_rolling = df_last_rolling.reindex(columns=selected_features)\n",
    "\n",
    "\n",
    "        X_future = df_last_rolling\n",
    "\n",
    "        display(X_future)\n",
    "\n",
    "        future_predictions = model.predict(X_future)\n",
    "        fga_prediction_results[player] = player , future_predictions[0].round(1)\n",
    "\n",
    "    return fga_prediction_results\n",
    "\n",
    "results = fga_prediction(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path)\n",
    "\n",
    "\n",
    "for player, fga_predictions in results.items():\n",
    "    print(fga_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_function import fga_prediction\n",
    "\n",
    "\n",
    "SAS = {'Chris Paul': 'SAS',\"De'Aaron Fox\": 'SAS', \"Devin Vassell\": 'SAS',\"Harrison Barnes\": 'SAS'}\n",
    "OKC = { 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC', 'Shai Gilgeous-Alexander':'OKC'}\n",
    "\n",
    "player_names = SAS\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "results = fga_prediction(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path)\n",
    "\n",
    "\n",
    "for player, fga_predictions in results.items():\n",
    "    print(fga_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_path(base_path, **Kwargs):\n",
    "    # Replace placeholders with actual values\n",
    "    for key, value in Kwargs.items():\n",
    "        base_path=base_path.replace(f\"{{{key}}}\", str(value))\n",
    "    return base_path\n",
    "\n",
    "base_path = \"/data/{year}/{month}/{day}/file.txt\"\n",
    "kwargs = {'year': 2025, 'month': '02', 'day': '10'}\n",
    "year = 2025\n",
    "build_data_path(base_path, year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "schedule_df = pd.read_csv(\"D:/nba_scheduled_csv/schedule_csv_2025/OKC_schedule_content.csv\")\n",
    "\n",
    "schedule_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fga_prediction(player_names: dict, date_list: list, usage_path, player_base_path, defense_base_path, schedule_base_path):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list,usage_path,player_base_path, defense_base_path)\n",
    "\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # print(schedule_df)\n",
    "\n",
    "    for player, df in fga_prediction_data.items():\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "        features = ['PACE', 'team_pace', 'USG', 'DefRtg','MIN_x', 'home_away', 'Date_in_Seconds','OffRtg', 'team_offrtg']\n",
    "        target = 'FGA'\n",
    "\n",
    "\n",
    "        # Continue with your existing operations\n",
    "        timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "        test_data =  df[df['Date_in_Seconds'] >= timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "\n",
    "\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[target]\n",
    "        X_test = test_data[features]\n",
    "        y_test = test_data[target]\n",
    "\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        ###### predicting Minutes ##########\n",
    "        alpha = 0.2\n",
    "\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "\n",
    "        last_actual = df['MIN_x'].iloc[-1]  # Last known FGA\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]  # Last smoothed value\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = next_value.round(2)\n",
    "\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1] \n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, ['TEAM','PACE', 'DefRtg', 'OffRtg']]\n",
    "\n",
    "        # display(df_for_schedule)\n",
    "\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "        # print(first_team)\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "        # print(schedule_team_result)\n",
    "\n",
    "        schedule_defrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'DefRtg'].values[0]\n",
    "\n",
    "        schedule_pace = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'PACE'].values[0]\n",
    "\n",
    "        schedule_offrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'OffRtg'].values[0]\n",
    "\n",
    "        # print(\"dfrtg:\",schedule_defrtg)\n",
    "        # print(\"pace\",schedule_pace)\n",
    "        # print(\"offrtg\",schedule_offrtg)\n",
    "\n",
    "        # This is to turn the first date in schedule into seconds\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "\n",
    "        # This is to turn the home and away games into a 1 or a zero -> away is 1 and anything is zero\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # display(schedule_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X_future = pd.DataFrame({\n",
    "        # 'EWMA_FGA_2': [next_value], \n",
    "        'PACE':[schedule_pace], \n",
    "        'team_pace':[df['team_pace'].iloc[-1]], \n",
    "        'USG':[df['USG'].iloc[-1]],\n",
    "        'DefRtg':[schedule_defrtg],\n",
    "        'MIN_x':[next_value], \n",
    "        'home_away':[schedule_df['home_away'].iloc[0]],\n",
    "        'Date_in_Seconds':[schedule_df['Date_in_Seconds'].iloc[0]],\n",
    "        'OffRtg':[df['OffRtg'].iloc[-1]],\n",
    "        'team_offrtg': [schedule_offrtg]\n",
    "        })\n",
    "\n",
    "        display(X_future)\n",
    "\n",
    "        future_predictions = model.predict(X_future)\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"this is future\",future_predictions)\n",
    "\n",
    "        fga_prediction_results.update({player:future_predictions[0]})\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return fga_prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import his_player_defense_data, current_player_defense_data, build_data_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def his_usage_team(player_names: dict, date_list: list, usage_path,player_base_path,defense_base_path):\n",
    "    current_player_dic = {}\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        current_player_frames =[]\n",
    "\n",
    "        for date in date_list:\n",
    "            usage_path =build_data_path(usage_path,date=date)\n",
    "            usage_data = pd.read_csv(usage_path)\n",
    "\n",
    "            #merging player and defense dat into one\n",
    "            merged_data, current_defense_df = his_player_defense_data(player_base_path,defense_base_path,player,date)\n",
    "\n",
    "            #adding season to usage_data\n",
    "            usage_data['season'] = date\n",
    "\n",
    "            #Getting the player usage percentage for usage data and adding to merge\n",
    "            player_usage = usage_data.loc[usage_data['Player'] == player, 'USG%'].values[0]\n",
    "            merged_data['USG'] = player_usage\n",
    "\n",
    "            #adding the current player team pace\n",
    "            team_stat = current_defense_df.loc[current_defense_df['TEAM'] == team, 'PACE'].values[0]\n",
    "            merged_data[\"team_pace\"] = team_stat\n",
    "\n",
    "            # adding current player team OffRtg\n",
    "            team_offrtg = current_defense_df.loc[current_defense_df['TEAM'] == team, 'OffRtg'].values[0]\n",
    "            merged_data[\"team_offrtg\"] = team_offrtg\n",
    "\n",
    "            team_poss = current_defense_df.loc[current_defense_df['TEAM'] == team, 'POSS'].values[0]\n",
    "            merged_data[\"team_poss\"] = team_poss\n",
    "            \n",
    "            # Exclude rows where the TEAM column matches the given team\n",
    "            merged_data = merged_data[merged_data['TEAM'] != team]\n",
    "\n",
    "\n",
    "            # merged_data = merged_data[['season','Date', 'Home/Away_game' ,'Matchup' ,'PTS','MIN_x', 'Team', 'TEAM', 'FGA', 'USG', 'DefRtg', 'PACE','team_pace']]\n",
    "\n",
    "            # Turn date into seconds\n",
    "            merged_data['Date_in_Seconds'] = pd.to_datetime(merged_data['Date']).astype('int64') // 10**9\n",
    "            merged_data = merged_data.sort_values(by=\"Date_in_Seconds\")\n",
    "\n",
    "\n",
    "            # Turn Home/Away game into 1 and 0\n",
    "            merged_data['home_away'] = merged_data['Home/Away_game'].apply(lambda x: 1 if x == 'Away' else 0)\n",
    "            # Dropping duplicates\n",
    "            merged_data = merged_data.drop_duplicates()\n",
    "            \n",
    "            # Append the DataFrame for this date to the player's list\n",
    "            current_player_frames.append(merged_data)\n",
    "\n",
    "        # Combine all dates for the current player into one DataFrame\n",
    "        current_player_dic[player] = pd.concat(current_player_frames, ignore_index=True)\n",
    "\n",
    "\n",
    "    return current_player_dic, current_defense_df\n",
    "\n",
    "\n",
    "player_names = { 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC', 'Shai Gilgeous-Alexander':'OKC'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "usage_path = \"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\"\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "\n",
    "def fga_prediction(player_names: dict, date_list: list, usage_path, player_base_path, defense_base_path, schedule_base_path):\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list, usage_path, player_base_path, defense_base_path)\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        # Get schedule data for the player's team\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "        \n",
    "        # Get player-specific prediction data\n",
    "\n",
    "        df = fga_prediction_data[player]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Model training and prediction code\n",
    "        features = ['PACE', 'team_pace', 'USG', 'DefRtg', 'MIN_x', 'home_away', 'Date_in_Seconds', 'OffRtg', 'team_offrtg']\n",
    "        target = 'FGA'\n",
    "\n",
    "        timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]\n",
    "        test_data = df[df['Date_in_Seconds'] >= timestamp]\n",
    "\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[target]\n",
    "        X_test = test_data[features]\n",
    "        y_test = test_data[target]\n",
    "\n",
    "        # Initialize Scaler\n",
    "        scaler = StandardScaler()\n",
    "        # Transform Data\n",
    "        scaled_data_x = scaler.fit_transform(X_train)\n",
    "        scaled_data_y = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "        X_train = pd.DataFrame(scaled_data_x, columns=X_train.columns)     \n",
    "        y_train = pd.DataFrame(scaled_data_y, columns=['features'])   \n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f\"{player}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        # EWMA calculation for minutes\n",
    "        alpha = 0.2\n",
    "        df['EWMA_MIN'] = df['MIN_x'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "        last_actual = df['MIN_x'].iloc[-1]\n",
    "        last_smoothed = df['EWMA_MIN'].iloc[-1]\n",
    "        next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "        next_value = round(next_value, 2)\n",
    "\n",
    "        # Get defensive stats for the scheduled team\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1]\n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, ['TEAM', 'PACE', 'DefRtg', 'OffRtg']]\n",
    "\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "        schedule_defrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'DefRtg'].values[0]\n",
    "        schedule_pace = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'PACE'].values[0]\n",
    "        schedule_offrtg = df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, 'OffRtg'].values[0]\n",
    "\n",
    "        # Convert schedule dates to seconds\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "        # Create future prediction dataframe\n",
    "        X_future = pd.DataFrame({\n",
    "            'PACE': [schedule_pace],\n",
    "            'team_pace': [df['team_pace'].iloc[-1]],\n",
    "            'USG': [df['USG'].iloc[-1]],\n",
    "            'DefRtg': [schedule_defrtg],\n",
    "            'MIN_x': [next_value],\n",
    "            'home_away': [schedule_df['home_away'].iloc[0]],\n",
    "            'Date_in_Seconds': [schedule_df['Date_in_Seconds'].iloc[0]],\n",
    "            'OffRtg': [df['OffRtg'].iloc[-1]],\n",
    "            'team_offrtg': [schedule_offrtg]\n",
    "        })\n",
    "\n",
    "        future_predictions = model.predict(X_future)\n",
    "        fga_prediction_results[player] = future_predictions[0]\n",
    "\n",
    "    return fga_prediction_results\n",
    "\n",
    "results = fga_prediction(player_names, date_list, usage_path, player_base_path, defense_base_path, schedule_base_path)\n",
    "\n",
    "\n",
    "for player, fga_predictions in results.items():\n",
    "    print(fga_predictions)\n",
    "   \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_functions as data_functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.invalidate_caches()\n",
    "from data_functions import his_player_defense_data, current_player_defense_data\n",
    "\n",
    "#\"D:\\nba_player_csv_current\\season_2024-25\\all_quarters\\Alex Caruso_content.csv\"\n",
    "#\"D:\\nba_defense_csv_current\\defense_csv_2024-25\\all_quarter_defense_content.csv\"\n",
    "#\"D:\\nba_scheduled_csv\\schedule_csv_2025\\ATL_schedule_content.csv\"\n",
    "\n",
    "player_names = {'Shai Gilgeous-Alexander':'OKC', 'Alex Caruso':'OKC', 'Isaiah Hartenstein':'OKC'}\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "# usage_data = f\"D:/nba_usage_csv_current/usage_csv_{date}/{date}_content.csv\"\n",
    "\n",
    "\n",
    "\n",
    "current_player_dic = {}\n",
    "\n",
    "for player, team in player_names.items():\n",
    "  current_player_frames = []\n",
    "\n",
    "  for date in date_list:\n",
    "    usage_data = pd.read_csv(f\"D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv\")  \n",
    "\n",
    "    # use current_player function to to merge datat\n",
    "    merged_data, current_player_defense = his_player_defense_data(player_base_path,defense_base_path,player,date)\n",
    "\n",
    "    # Add the season column to usage_data\n",
    "    usage_data['season'] = date\n",
    "    \n",
    "    # Get the player's usage percentage from the usage data\n",
    "    # (Assumes that there is exactly one matching row)\n",
    "    player_usage = usage_data.loc[usage_data['Player'] == player, 'USG%'].values[0]\n",
    "    merged_data['USG'] = player_usage\n",
    "\n",
    "\n",
    "    # adding current player team pace\n",
    "    team_stat = current_player_defense.loc[current_player_defense['TEAM'] == team, 'PACE'].values[0]\n",
    "    merged_data[\"team_pace\"] = team_stat\n",
    "\n",
    "    # display(current_player_defense)\n",
    "\n",
    "    # adding current player team OffRtg\n",
    "    team_offrtg = current_player_defense.loc[current_player_defense['TEAM'] == team, 'OffRtg'].values[0]\n",
    "    merged_data[\"team_offrtg\"] = team_offrtg\n",
    "\n",
    "    team_poss = current_player_defense.loc[current_player_defense['TEAM']== team, 'POSS'].values[0]\n",
    "    merged_data[\"team_poss\"] = team_poss\n",
    "\n",
    "    # Exclude rows where the TEAM column matches the given team\n",
    "    merged_data = merged_data[merged_data['TEAM'] != team]\n",
    "    # display(merged_data.head(5))\n",
    "\n",
    "    # merged_data = merged_data[['season','Date', 'Home/Away_game' ,'Matchup' ,'PTS','MIN_x', 'Team', 'TEAM', 'FGA', 'USG', 'DefRtg', 'PACE','team_pace']]\n",
    "\n",
    "    # Turn date into seconds\n",
    "    merged_data['Date_in_Seconds'] = pd.to_datetime(merged_data['Date']).astype('int64') // 10**9\n",
    "    merged_data = merged_data.sort_values(by=\"Date_in_Seconds\")\n",
    "\n",
    "    # Turn Home/Away game into 1 and 0\n",
    "    merged_data['home_away'] = merged_data['Home/Away_game'].apply(lambda x: 1 if x == 'Away' else 0)\n",
    "    # Dropping duplicates\n",
    "    merged_data = merged_data.drop_duplicates()\n",
    "    \n",
    "    # Append the DataFrame for this date to the player's list\n",
    "    current_player_frames.append(merged_data)\n",
    "\n",
    "  # Combine all dates for the current player into one DataFrame\n",
    "  current_player_dic[player] = pd.concat(current_player_frames, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "specific_player = 'Shai Gilgeous-Alexander'\n",
    "for player, df in current_player_dic.items():\n",
    "\n",
    "    print(f\"\\nData for {player}:\")\n",
    "    df['FGA_rolling_3'] = df['FGA'].rolling(window=3).mean()\n",
    "\n",
    "\n",
    "\n",
    "    alpha = 0.2\n",
    "\n",
    "    df['EWMA_FGA'] = df['FGA'].ewm(span=(2/(1-alpha)-1), adjust=False).mean()\n",
    "\n",
    "    df['EWMA_FGA_2'] = df['FGA'].ewm(span=(2/alpha - 1), adjust=False).mean()\n",
    "\n",
    "    # alpha = 0.2  # Example smoothing factor\n",
    "    df['Exp_smooth'] = 21  # Initialize column\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        df.loc[i, 'Exp_smooth'] = alpha * df.loc[i, 'FGA'] + (1 - alpha) * df.loc[i - 1, 'Exp_smooth']\n",
    "\n",
    "    df_act = df\n",
    "\n",
    "    # display(df_act)\n",
    "\n",
    "    # display(df)\n",
    "    df = df.head(149)\n",
    "\n",
    "    value_fga_list = []\n",
    "    moving_average_list = []\n",
    "    next_next_value_list = []\n",
    "    date_list = []\n",
    "    \n",
    "    for value_fga, moving_average, date in zip(df['FGA'],df['EWMA_FGA_2'],df['Date']):\n",
    "       value_fga_list.append(value_fga)\n",
    "       moving_average_list.append(moving_average)\n",
    "       #print(\"this is actual:\",value_fga, \"this is last_predicted\",moving_average)\n",
    "       next_next_value = alpha * value_fga + (1 - alpha) * moving_average\n",
    "       next_next_value_list.append(next_next_value)\n",
    "       date_list.append(date)\n",
    "       #print(\"this is next:\",next_next_value)\n",
    "       dataframe_dic= {'Date':date_list,'Actual_FGA': value_fga_list, 'Moving_average':moving_average_list, 'Next':next_next_value_list}\n",
    "       dataframe = pd.DataFrame(dataframe_dic)\n",
    "      #  dataframe['Next'] = dataframe['Next'].shift(1)\n",
    "\n",
    "    # display(dataframe)\n",
    "\n",
    "\n",
    "    # Predict the next (11th) value\n",
    "    last_actual = df['FGA'].iloc[-1]  # Last known FGA\n",
    "    last_smoothed = df['EWMA_FGA_2'].iloc[-1]  # Last smoothed value\n",
    "    next_value = alpha * last_actual + (1 - alpha) * last_smoothed\n",
    "\n",
    "\n",
    "    # Print and add the prediction\n",
    "    print(f\"Predicted value: {next_value}\")\n",
    "\n",
    "    # display(df)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "    features = ['PACE', 'team_pace', 'USG', 'DefRtg','MIN_x', 'home_away', 'Date_in_Seconds','OffRtg', 'team_offrtg']\n",
    "    target = 'FGA'\n",
    "\n",
    "\n",
    "     # Continue with your existing operations\n",
    "    timestamp = int(pd.Timestamp('2024-12-31').timestamp())\n",
    "    train_data = df[df['Date_in_Seconds'] < timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "    test_data =  df[df['Date_in_Seconds'] >= timestamp]  # Replace '2023-01-01' with the corresponding timestamp\n",
    "\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[target]\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # print(y_pred)\n",
    "\n",
    "     # Compare predictions with actual points\n",
    "    predicted_vs_actual = pd.DataFrame({\n",
    "        \"Date\": test_data['Date'],  \n",
    "        \"Matchup\": test_data['Matchup'],  \n",
    "        \"Predicted Points\": y_pred.round(1), \n",
    "        \"Actual Points\": y_test}).reset_index(drop=True)\n",
    "    \n",
    "    display(predicted_vs_actual)\n",
    "\n",
    "    X_future = pd.DataFrame({\n",
    "    # 'EWMA_FGA_2': [next_value], \n",
    "    'PACE':[df['PACE'].iloc[-1]], \n",
    "    'team_pace':[df['team_pace'].iloc[-1]], \n",
    "    'USG':[df['USG'].iloc[-1]],\n",
    "    'DefRtg':[df['DefRtg'].iloc[-1]],\n",
    "    'MIN_x':[30.09], \n",
    "    'home_away':[1],\n",
    "    'Date_in_Seconds':[1738368000],\n",
    "    'OffRtg':[df['OffRtg'].iloc[-1]],\n",
    "    'team_offrtg': [df['team_offrtg'].iloc[-1]]\n",
    "    })\n",
    "    \n",
    "    future_predictions = model.predict(X_future)\n",
    "\n",
    "    print(\"this is future\",future_predictions)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f\"MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Drop NaN values (first row of 'Next' is NaN due to shift)\n",
    "    rmse_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(((rmse_df['Actual_FGA'] - rmse_df['Next']) ** 2).mean())\n",
    "\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "\n",
    "    # Drop NaN values (due to shift)\n",
    "    comparison_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Total number of valid comparisons\n",
    "    total = len(comparison_df)\n",
    "\n",
    "    # Count occurrences\n",
    "    higher_count = (comparison_df['Next'] > comparison_df['Actual_FGA']).sum()\n",
    "    lower_count = (comparison_df['Next'] < comparison_df['Actual_FGA']).sum()\n",
    "    equal_count = (comparison_df['Next'] == comparison_df['Actual_FGA']).sum()\n",
    "\n",
    "    # Calculate percentages\n",
    "    higher_percent = (higher_count / total) * 100\n",
    "    lower_percent = (lower_count / total) * 100\n",
    "    equal_percent = (equal_count / total) * 100\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Percentage of predictions HIGHER than actual: {higher_percent:.2f}%\")\n",
    "    print(f\"Percentage of predictions LOWER than actual: {lower_percent:.2f}%\")\n",
    "    print(f\"Percentage of predictions EQUAL to actual: {equal_percent:.2f}%\")\n",
    "\n",
    "\n",
    "    comparison_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Filter cases where Next is higher than Actual\n",
    "    higher_cases = comparison_df[comparison_df['Next'] > comparison_df['Actual_FGA']]\n",
    "    higher_difference_avg = (higher_cases['Next'] - higher_cases['Actual_FGA']).mean()\n",
    "\n",
    "    # Filter cases where Next is lower than Actual\n",
    "    lower_cases = comparison_df[comparison_df['Next'] < comparison_df['Actual_FGA']]\n",
    "    lower_difference_avg = (lower_cases['Actual_FGA'] - lower_cases['Next']).mean()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average difference when prediction is HIGHER: {higher_difference_avg:.2f}\")\n",
    "    print(f\"Average difference when prediction is LOWER: {lower_difference_avg:.2f}\")\n",
    "\n",
    "    # Drop NaN values\n",
    "    comparison_df = dataframe.dropna(subset=['Actual_FGA', 'Next'])\n",
    "\n",
    "    # Compute Mean Error (ME)\n",
    "    mean_error = (comparison_df['Next'] - comparison_df['Actual_FGA']).mean()\n",
    "\n",
    "    # Print result\n",
    "    print(f\"Mean Error (ME): {mean_error:.2f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
