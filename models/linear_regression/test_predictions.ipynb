{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas\n",
    "from feature_function import select_features\n",
    "from data_functions import his_player_defense_data, current_player_defense_data, build_data_path, his_usage_team\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def prediction(player_names: dict, date_list: list, stats_path: dict, player_base_path, defense_base_path, schedule_base_path ,selected_feature_target, prediction_target):\n",
    "    \"\"\"\n",
    "    Predicts future data for NBA players using historical data and rolling averages.\n",
    "\n",
    "    Parameters:\n",
    "        player_names (dict): Dictionary mapping player names to their respective teams.\n",
    "        date_list (list): List of dates to consider for analysis.\n",
    "        usage_path (str): Path to player usage data.\n",
    "        player_base_path (str): Path to player statistics data.\n",
    "        defense_base_path (str): Path to team defense statistics.\n",
    "        schedule_base_path (str): Path to team schedules.\n",
    "        selected_feature_target (str): Target feature for selecting model input features.\n",
    "        prediction_target (str): The feature to be predicted (e.g., FGA).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing predicted values and RMSE for each player.\n",
    "    \"\"\"\n",
    "    fga_prediction_data, df_defense = his_usage_team(player_names, date_list, stats_path, player_base_path, defense_base_path)\n",
    "    fga_prediction_results = {}\n",
    "\n",
    "    # Select the best features for each player\n",
    "    feature_dic = select_features(player_names, date_list, stats_path, player_base_path, defense_base_path, selected_feature_target)\n",
    "\n",
    "    for player, team in player_names.items():\n",
    "        # Load schedule data for the player's team\n",
    "        schedule_path = build_data_path(schedule_base_path, schedule_team=team)\n",
    "        schedule_df = pd.read_csv(schedule_path)\n",
    "\n",
    "        # Retrieve player-specific prediction data\n",
    "        df = fga_prediction_data[player]\n",
    "\n",
    "\n",
    "        features = feature_dic[player] \n",
    "\n",
    "        # some players can't connect to the his_usage datatframe well I don't why\n",
    "        features = [feature for feature in features if feature in df.columns]\n",
    "        \n",
    "        if not features:\n",
    "            print(f\"No valid features found for {player} for predicting {prediction_target}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        target = prediction_target\n",
    "\n",
    "        # print(f\"Available columns for {player}: {df.columns.tolist()}\")\n",
    "        # print(f\"Selected features for {player}: {features}\")\n",
    "\n",
    "        # Split data into training and testing sets based on a timestamp\n",
    "        timestamp = int(pd.Timestamp('2025-03-10').timestamp())\n",
    "        train_data = df[df['Date_in_Seconds'] < timestamp]\n",
    "        test_data = df[df['Date_in_Seconds'] >= timestamp]\n",
    "\n",
    "        X_train = train_data[features].fillna(0)\n",
    "        y_train = train_data[target].fillna(0)\n",
    "        X_test = test_data[features].fillna(0)\n",
    "        y_test = test_data[target].fillna(0) \n",
    "\n",
    "        # display(X_train.head(1))\n",
    "        # print(f\"X_train shape: {X_train.shape}\")\n",
    "        # print(f\"y_train shape: {y_train.shape}\")\n",
    "        # print(X_train.head())  # View first few rows\n",
    "        # print(y_train.head())  # View first few rows\n",
    "\n",
    "        # print(features)  # Check selected feature names\n",
    "        # print(X_train.columns)  # See available columns\n",
    "\n",
    "\n",
    "        if not features:  # If feature_columns is an empty list\n",
    "            print(f\"Skipping training: No selected {target} features.\")\n",
    "            sys.exit(1) \n",
    "\n",
    "\n",
    "\n",
    "        # Train linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate error metrics\n",
    "        # mae = mean_absolute_error(y_test, y_pred)\n",
    "        # mse = mean_squared_error(y_test, y_pred)\n",
    "        # rmse = np.sqrt(mse)\n",
    "\n",
    "        # print(f\"{player}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        # Define feature exclusion lists\n",
    "        exclude_features = ['RANK', 'OffRtg', 'W', 'L', 'DefRtg', 'NetRtg', 'AST%', 'AST/TO', 'ASTRatio',\n",
    "                            'OREB%', 'DREB%', 'REB%', 'TOV%', 'eFG%', 'TS%', 'PACE', 'POSS', 'TEAM', 'PIE']\n",
    "        exclude_features_schedule = ['home_away', 'schedule_team', 'DATE', 'location', 'season_defense']\n",
    "\n",
    "        # Convert schedule dates to timestamp format\n",
    "        schedule_df['Date_in_Seconds'] = pd.to_datetime(schedule_df['DATE']).astype('int64') // 10**9\n",
    "        schedule_df['home_away'] = schedule_df['location'].apply(lambda x: 1 if x == 'away' else 0)\n",
    "\n",
    "        # Extract defensive stats for the scheduled team\n",
    "        last_season = df_defense[\"season_defense\"].iloc[-1]\n",
    "        df_for_schedule = df_defense.loc[df_defense[\"season_defense\"] == last_season, exclude_features]\n",
    "        first_team = schedule_df['schedule_team'].iloc[0]\n",
    "        schedule_team_result = schedule_df.loc[schedule_df['schedule_team'] == first_team, 'schedule_team'].values[0]\n",
    "        schedule_values = {feature: df_for_schedule.loc[df_for_schedule['TEAM'] == schedule_team_result, feature].values[0] \n",
    "                           for feature in exclude_features if feature in df_for_schedule.columns}\n",
    "        \n",
    " \n",
    "        # print(schedule_values)  # Debugging: Ensure schedule values are correctly retrieved\n",
    "\n",
    "        # Extract rolling average features\n",
    "        rolling_features = [col for col in features if col not in exclude_features]\n",
    "        for col in rolling_features:\n",
    "            df[f'{col}'] = df[col].rolling(window=20).mean().fillna(0).astype(int)\n",
    "        df_last_rolling = df.iloc[[-1]][[f'{col}' for col in rolling_features]].reset_index(drop=True)\n",
    "\n",
    "        # Update rolling feature set with scheduled team values\n",
    "        for value in features:\n",
    "            if value in exclude_features:\n",
    "                df_last_rolling[value] = schedule_values.get(value)\n",
    "        for value in features:\n",
    "            if value in exclude_features_schedule:\n",
    "                df_last_rolling[value] = schedule_df[value].iloc[0]\n",
    "\n",
    "        # Ensure feature order is consistent with model input\n",
    "        df_last_rolling = df_last_rolling.reindex(columns=features)\n",
    "        X_future = df_last_rolling\n",
    "\n",
    "        # display(X_future.head(10))\n",
    "        # Step 1: Calculate mean and standard deviation of the target variable (PTS, REB, etc.)\n",
    "        mean_target = y_train.mean()\n",
    "        std_target = y_train.std()\n",
    "\n",
    "        # Step 2: Define reasonable bounds (e.g., within 3 standard deviations)\n",
    "        lower_bound = mean_target - 3 * std_target\n",
    "        upper_bound = mean_target + 3 * std_target\n",
    "\n",
    "        \n",
    "\n",
    "        # future predictions happens here\n",
    "        future_predictions = model.predict(X_future).astype('int')\n",
    "\n",
    "        future_predictions = np.clip(future_predictions, lower_bound, upper_bound).astype('int')\n",
    "\n",
    "\n",
    "\n",
    "        # creating rolling mean average\n",
    "        df[f\"Rolling_Mean_{target}\"] = df[target].rolling(window=20).mean()\n",
    "        df[f\"Rolling_Std_{target}\"] = df[target].rolling(window=20).std()\n",
    "        df[f\"Rolling_CV_{target}\"] = df[f\"Rolling_Std_{target}\"] / df[f\"Rolling_Mean_{target}\"]\n",
    "\n",
    "        rounded_future_prediction = abs(future_predictions[0])\n",
    "\n",
    "        # print(player)\n",
    "        # display(X_future.head(10))\n",
    "        # print(player, target, rounded_future_prediction)\n",
    "        # display(df[[f\"Rolling_CV_{target}\"]].tail(1))\n",
    "\n",
    "        if pd.isna(df[f\"Rolling_CV_{target}\"].iloc[-1]) or np.isinf(df[f\"Rolling_CV_{target}\"].iloc[-1]):\n",
    "            df.loc[df.index[-1], f\"Rolling_CV_{target}\"] = 0\n",
    "\n",
    "        rolling_cv = df[f\"Rolling_CV_{target}\"].iloc[-1]\n",
    "        highest_cv_seen = df[f\"Rolling_CV_{target}\"].max()\n",
    "\n",
    "        cv_fluctuate = rolling_cv * rounded_future_prediction\n",
    "\n",
    "        if cv_fluctuate > rounded_future_prediction:\n",
    "            cv_low_prediction = abs(cv_fluctuate - rounded_future_prediction)\n",
    "\n",
    "        cv_low_prediction = abs(rounded_future_prediction- cv_fluctuate)\n",
    "        cv_high_prediction = rounded_future_prediction + cv_fluctuate\n",
    "\n",
    "        player_prediction = f\"{cv_low_prediction.astype('int')} - {rounded_future_prediction} - {cv_high_prediction.astype('int')}\"\n",
    "\n",
    "        \n",
    "\n",
    "        if rolling_cv > 1:\n",
    "            confidence_score = max(0, 1 - (rolling_cv / highest_cv_seen))\n",
    "        else:\n",
    "            confidence_score = 1 - rolling_cv  # More stability → Higher confidence\n",
    "\n",
    "        confidence_score_percentage = round(confidence_score * 100, 2)\n",
    "\n",
    "\n",
    "        lower_bound, upper_bound = cv_low_prediction, rounded_future_prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Get last 10 games\n",
    "        recent_games = df[target].tail(10)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Fit a linear regression (x = game number, y = points)\n",
    "        x = np.arange(1, len(recent_games) + 1)\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, recent_games)\n",
    "\n",
    "        long_term_cv = df[\"PTS\"].rolling(10).std() / df[\"PTS\"].rolling(10).mean()\n",
    "\n",
    "        # Set dynamic base threshold (scaled by long-term CV)\n",
    "        base_threshold = max(0.2, min(0.6, 0.3 + 0.2 * long_term_cv.iloc[-1]))\n",
    "\n",
    "        # Compute dynamic middle threshold (adjusted for rolling CV)\n",
    "        middle_threshold = max(0.2, min(0.8, base_threshold * (1 + rolling_cv)))\n",
    "        \n",
    "        # Check if the slope is close to zero (i.e., in the middle)\n",
    "        if -middle_threshold <= slope <= middle_threshold:\n",
    "            trend_status = \"stable\"\n",
    "        elif slope > 0:\n",
    "            trend_status = \"trending up\"\n",
    "        else:\n",
    "            trend_status = \"trending down\"\n",
    "\n",
    "\n",
    "        ##### this is for safebet column ############\n",
    "        import math\n",
    "        # Step 1: Calculate the midpoint of the range\n",
    "        midpoint = (lower_bound + upper_bound) / 2\n",
    "        midpoint = math.floor(midpoint)\n",
    "    \n",
    "        \n",
    "        # Step 2: Adjust the prediction based on confidence score\n",
    "        if confidence_score_percentage > 60:\n",
    "            # High confidence - stick closer to midpoint\n",
    "            if trend_status == \"trending up\":\n",
    "                # Trending up - lean towards the higher end\n",
    "                exact_point = round(midpoint)\n",
    "            elif trend_status == \"trending down\":\n",
    "                # Trending down - lean towards the lower end\n",
    "                exact_point = lower_bound\n",
    "            else:\n",
    "                # Stable - pick midpoint or the closest round number\n",
    "                exact_point = round(midpoint)\n",
    "        else:\n",
    "            # Low confidence - lean more conservatively towards the edges\n",
    "            if trend_status == \"trending up\":\n",
    "                # Trending up - lean towards the higher end\n",
    "                exact_point = round(midpoint + 1)  # Slight bias to upper end\n",
    "            elif trend_status == \"trending down\":\n",
    "                # Trending down - lean towards the lower end\n",
    "                exact_point = round(midpoint - 1)  # Slight bias to lower end\n",
    "            else:\n",
    "                # Stable - pick midpoint but be cautious (lean lower)\n",
    "                exact_point = round(midpoint - 1)\n",
    "\n",
    "        exact_point = int(exact_point)\n",
    "\n",
    "        if exact_point == -1:\n",
    "            exact_point = 0\n",
    "\n",
    "        if target == 'FGA':\n",
    "            target = 'PTS'\n",
    "\n",
    "        # trend_df = df[target].tail(10).tolist()\n",
    "        trend_df = df[target].tail(10).tolist()[::-1]\n",
    "\n",
    "\n",
    "\n",
    "        fga_prediction_results[player] = [team,player_prediction,confidence_score_percentage,trend_df]\n",
    "\n",
    "        \n",
    "        \n",
    "        df_results = pd.DataFrame.from_dict(fga_prediction_results, orient='index', columns=['team',target,f'confidence_level_{target}' ,f'recentgames_{target}'])\n",
    "        # Reset index and rename it properly\n",
    "        df_results.reset_index(inplace=True)\n",
    "        df_results.rename(columns={'index': 'Player'}, inplace=True)\n",
    "        today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        #create a directory if one doesn't exist\n",
    "        directory = f'prediction_output/{target}_outputs'\n",
    "        os.makedirs(directory, exist_ok=True)    \n",
    "        df_results.to_csv(f'{directory}/{target}_output_{today_date}.csv', index=False)\n",
    "        # display(df_results)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-03, tolerance: 2.055e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.194e-02, tolerance: 5.888e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.261e-02, tolerance: 2.622e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e-03, tolerance: 6.590e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e-01, tolerance: 7.448e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-02, tolerance: 1.015e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e-01, tolerance: 2.634e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e-02, tolerance: 3.180e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e-01, tolerance: 1.420e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.420e+00, tolerance: 1.407e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.926e-02, tolerance: 9.375e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.130e-02, tolerance: 1.260e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e-01, tolerance: 5.786e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.691e-01, tolerance: 7.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e-02, tolerance: 1.502e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e-01, tolerance: 1.283e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.898e-01, tolerance: 1.335e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2022-23, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Zaccharie Risacher on 2023-24, skipping.\n",
      "Skipping merge for Zaccharie Risacher on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Mouhamed Gueye on 2022-23, skipping.\n",
      "Skipping merge for Mouhamed Gueye on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Tyrese Martin on 2023-24, skipping.\n",
      "Skipping merge for Tyrese Martin on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2022-23, skipping.\n",
      "Skipping merge for Jamison Battle on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamison Battle on 2023-24, skipping.\n",
      "Skipping merge for Jamison Battle on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2022-23, skipping.\n",
      "Skipping merge for Jamal Shead on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Jamal Shead on 2023-24, skipping.\n",
      "Skipping merge for Jamal Shead on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Toumani Camara on 2022-23, skipping.\n",
      "Skipping merge for Toumani Camara on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2022-23, skipping.\n",
      "Skipping merge for Donovan Clingan on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Donovan Clingan on 2023-24, skipping.\n",
      "Skipping merge for Donovan Clingan on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for DaQuan Jeffries on 2022-23, skipping.\n",
      "Skipping merge for DaQuan Jeffries on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Miles Bridges on 2022-23, skipping.\n",
      "Skipping merge for Miles Bridges on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2022-23, skipping.\n",
      "Skipping merge for Cody Williams on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cody Williams on 2023-24, skipping.\n",
      "Skipping merge for Cody Williams on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2022-23, skipping.\n",
      "Skipping merge for Isaiah Collier on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Isaiah Collier on 2023-24, skipping.\n",
      "Skipping merge for Isaiah Collier on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Lauri Markkanen on 2022-23, skipping.\n",
      "Skipping merge for Lauri Markkanen on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2022-23, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Kyle Filipowski on 2023-24, skipping.\n",
      "Skipping merge for Kyle Filipowski on 2023-24 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Rudy Gobert on 2022-23, skipping.\n",
      "Skipping merge for Rudy Gobert on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Cason Wallace on 2022-23, skipping.\n",
      "Skipping merge for Cason Wallace on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n",
      "Player data missing for Chet Holmgren on 2022-23, skipping.\n",
      "Skipping merge for Chet Holmgren on 2022-23 due to missing data.\n",
      "defense data skipping defense merge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# from prediction import prediction\n",
    "\n",
    "\n",
    "\n",
    "players_teams = {\n",
    "    \"Dyson Daniels\": \"ATL\",\n",
    "    \"Zaccharie Risacher\": \"ATL\",\n",
    "    \"Trae Young\": \"ATL\",\n",
    "    \"Mouhamed Gueye\": \"ATL\",\n",
    "    \"Onyeka Okongwu\": \"ATL\",\n",
    "    \"Tyrese Martin\": \"BKN\",\n",
    "    \"Ziaire Williams\": \"BKN\",\n",
    "    \"Keon Johnson\": \"BKN\",\n",
    "    \"Cameron Johnson\": \"BKN\",\n",
    "    \"Nic Claxton\": \"BKN\",\n",
    "    \"Jamison Battle\": \"TOR\",\n",
    "    \"RJ Barrett\": \"TOR\",\n",
    "    \"Jamal Shead\": \"TOR\",\n",
    "    \"Scottie Barnes\": \"TOR\",\n",
    "    \"Jakob Poeltl\": \"TOR\",\n",
    "    \"Shaedon Sharpe\": \"POR\",\n",
    "    \"Toumani Camara\": \"POR\",\n",
    "    \"Anfernee Simons\": \"POR\",\n",
    "    \"Deni Avdija\": \"POR\",\n",
    "    \"Donovan Clingan\": \"POR\",\n",
    "    \"Josh Green\": \"CHA\",\n",
    "    \"DaQuan Jeffries\": \"CHA\",\n",
    "    \"LaMelo Ball\": \"CHA\",\n",
    "    \"Miles Bridges\": \"CHA\",\n",
    "    \"Mark Williams\": \"CHA\",\n",
    "    \"Bogdan Bogdanovic\": \"LAC\",\n",
    "    \"Kawhi Leonard\": \"LAC\",\n",
    "    \"James Harden\": \"LAC\",\n",
    "    \"Nicolas Batum\": \"LAC\",\n",
    "    \"Ivica Zubac\": \"LAC\",\n",
    "    \"Collin Sexton\": \"UTA\",\n",
    "    \"Cody Williams\": \"UTA\",\n",
    "    \"Isaiah Collier\": \"UTA\",\n",
    "    \"Lauri Markkanen\": \"UTA\",\n",
    "    \"Kyle Filipowski\": \"UTA\",\n",
    "    \"Anthony Edwards\": \"MIN\",\n",
    "    \"Jaden McDaniels\": \"MIN\",\n",
    "    \"Donte DiVincenzo\": \"MIN\",\n",
    "    \"Julius Randle\": \"MIN\",\n",
    "    \"Rudy Gobert\": \"MIN\",\n",
    "    \"Cason Wallace\": \"OKC\",\n",
    "    \"Aaron Wiggins\": \"OKC\",\n",
    "    \"Shai Gilgeous-Alexander\": \"OKC\",\n",
    "    \"Kenrich Williams\": \"OKC\",\n",
    "    \"Chet Holmgren\": \"OKC\",\n",
    "    \"Taurean Prince\": \"MIL\",\n",
    "    \"Kyle Kuzma\": \"MIL\",\n",
    "    \"Damian Lillard\": \"MIL\",\n",
    "    \"Giannis Antetokounmpo\": \"MIL\",\n",
    "    \"Brook Lopez\": \"MIL\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# remember to run mover\n",
    "# remember to check schedule csv\n",
    "import pandas as pd\n",
    "date_list = [\"2022-23\",\"2023-24\",\"2024-25\"]\n",
    "stats_path = {\n",
    "    'usage_path':'D:/nba_usage_csv_historic/usage_csv_{date}/{date}_content.csv',\n",
    "    'catch_shoot':\"D:/nba_tracking_data_csv/nba_csv_{date}/catch_shoot_content.csv\",\n",
    "    'drives':\"D:/nba_tracking_data_csv/nba_csv_{date}/drives_content.csv\",\n",
    "    'elbow_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/elbow_touch_content.csv\",\n",
    "    'paint_touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/paint_touch_content.csv\",\n",
    "    'passing':\"D:/nba_tracking_data_csv/nba_csv_{date}/passing_content.csv\",\n",
    "    'pullup':\"D:/nba_tracking_data_csv/nba_csv_{date}/pullup_content.csv\",\n",
    "    'shooting_efficiency':\"D:/nba_tracking_data_csv/nba_csv_{date}/shooting_efficiency_content.csv\",\n",
    "    'touches':\"D:/nba_tracking_data_csv/nba_csv_{date}/touches_content.csv\",\n",
    "    'tracking_post_ups_content':\"D:/nba_tracking_data_csv/nba_csv_{date}/tracking_post_ups_content.csv\"\n",
    "}\n",
    "schedule_base_path = \"D:/nba_scheduled_csv/schedule_csv_2025/{schedule_team}_schedule_content.csv\"\n",
    "player_base_path = \"D:/nba_player_csv_historic/season_{date}/all_quarters/{player}_content.csv\"\n",
    "defense_base_path = \"D:/nba_defense_history_csv/defense_csv_{date}/all_quarter_defense_content.csv\"\n",
    "\n",
    "results_reb = prediction(players_teams, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'REB','REB')\n",
    "results_ast = prediction(players_teams, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'AST','AST')\n",
    "results_pts = prediction(players_teams, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'PTS','PTS')\n",
    "results_3pm = prediction(players_teams, date_list, stats_path, player_base_path, defense_base_path, schedule_base_path,'3PM','3PM')\n",
    "results_pts = results_pts.rename(columns={'FGA': 'PTS'})\n",
    "\n",
    "\n",
    "\n",
    "# display(results_reb)\n",
    "# display(results_ast)\n",
    "# display(results_pts)\n",
    "# display(results_3pm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence scores for each group:\n",
      "Parlay 1: 67.07\n",
      "Parlay 2: 62.50\n",
      "Parlay 3: 80.97\n",
      "Parlay 4: 83.42\n",
      "Parlay 5: 78.75\n",
      "Parlay 6: 81.38\n",
      "Parlay 7: 62.88\n",
      "Parlay 8: 65.14\n",
      "Parlay 9: 77.60\n",
      "Parlay 10: 65.43\n",
      "Parlay 11: 73.77\n",
      "Parlay 12: 62.02\n",
      "\n",
      "\n",
      "Parlay 1: total confidence score: 67.07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Onyeka Okongwu</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REB</td>\n",
       "      <td>6 - 9 - 11</td>\n",
       "      <td>69.58</td>\n",
       "      <td>[10, 10, 5, 16, 13, 9, 12, 13, 9, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trae Young</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AST</td>\n",
       "      <td>7 - 11 - 14</td>\n",
       "      <td>67.76</td>\n",
       "      <td>[7, 12, 8, 16, 13, 15, 12, 8, 14, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trae Young</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PTS</td>\n",
       "      <td>15 - 25 - 34</td>\n",
       "      <td>63.88</td>\n",
       "      <td>[17, 35, 36, 22, 28, 12, 19, 17, 11, 38]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0  Onyeka Okongwu  ATL  REB    6 - 9 - 11       69.58      [10, 10, 5, 16, 13, 9, 12, 13, 9, 8]\n",
       "1      Trae Young  ATL  AST   7 - 11 - 14       67.76     [7, 12, 8, 16, 13, 15, 12, 8, 14, 13]\n",
       "2      Trae Young  ATL  PTS  15 - 25 - 34       63.88  [17, 35, 36, 22, 28, 12, 19, 17, 11, 38]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 2: total confidence score: 62.50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dyson Daniels</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REB</td>\n",
       "      <td>3 - 6 - 8</td>\n",
       "      <td>63.34</td>\n",
       "      <td>[6, 5, 6, 6, 4, 9, 3, 4, 5, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Onyeka Okongwu</td>\n",
       "      <td>ATL</td>\n",
       "      <td>3PM</td>\n",
       "      <td>0 - 0 - 0</td>\n",
       "      <td>62.93</td>\n",
       "      <td>[0, 1, 3, 0, 0, 0, 0, 1, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dyson Daniels</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AST</td>\n",
       "      <td>2 - 4 - 5</td>\n",
       "      <td>61.24</td>\n",
       "      <td>[5, 3, 9, 4, 5, 6, 7, 3, 5, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player team Stat Stat Range  Confidence                      recentgames\n",
       "0   Dyson Daniels  ATL  REB  3 - 6 - 8       63.34  [6, 5, 6, 6, 4, 9, 3, 4, 5, 11]\n",
       "1  Onyeka Okongwu  ATL  3PM  0 - 0 - 0       62.93   [0, 1, 3, 0, 0, 0, 0, 1, 1, 2]\n",
       "2   Dyson Daniels  ATL  AST  2 - 4 - 5       61.24   [5, 3, 9, 4, 5, 6, 7, 3, 5, 2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 3: total confidence score: 80.97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nic Claxton</td>\n",
       "      <td>BKN</td>\n",
       "      <td>3PM</td>\n",
       "      <td>0 - 0 - 0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cameron Johnson</td>\n",
       "      <td>BKN</td>\n",
       "      <td>PTS</td>\n",
       "      <td>12 - 16 - 19</td>\n",
       "      <td>78.54</td>\n",
       "      <td>[23, 16, 17, 18, 26, 17, 13, 14, 19, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nic Claxton</td>\n",
       "      <td>BKN</td>\n",
       "      <td>PTS</td>\n",
       "      <td>7 - 11 - 14</td>\n",
       "      <td>64.36</td>\n",
       "      <td>[18, 9, 12, 8, 8, 6, 9, 16, 8, 16]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0      Nic Claxton  BKN  3PM     0 - 0 - 0      100.00            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1  Cameron Johnson  BKN  PTS  12 - 16 - 19       78.54  [23, 16, 17, 18, 26, 17, 13, 14, 19, 17]\n",
       "2      Nic Claxton  BKN  PTS   7 - 11 - 14       64.36        [18, 9, 12, 8, 8, 6, 9, 16, 8, 16]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 4: total confidence score: 83.42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakob Poeltl</td>\n",
       "      <td>TOR</td>\n",
       "      <td>3PM</td>\n",
       "      <td>0 - 0 - 0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RJ Barrett</td>\n",
       "      <td>TOR</td>\n",
       "      <td>PTS</td>\n",
       "      <td>14 - 18 - 21</td>\n",
       "      <td>78.40</td>\n",
       "      <td>[17, 14, 23, 21, 22, 18, 16, 22, 23, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scottie Barnes</td>\n",
       "      <td>TOR</td>\n",
       "      <td>PTS</td>\n",
       "      <td>10 - 15 - 19</td>\n",
       "      <td>71.85</td>\n",
       "      <td>[20, 14, 18, 22, 17, 10, 24, 21, 20, 13]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0    Jakob Poeltl  TOR  3PM     0 - 0 - 0      100.00            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1      RJ Barrett  TOR  PTS  14 - 18 - 21       78.40  [17, 14, 23, 21, 22, 18, 16, 22, 23, 29]\n",
       "2  Scottie Barnes  TOR  PTS  10 - 15 - 19       71.85  [20, 14, 18, 22, 17, 10, 24, 21, 20, 13]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 5: total confidence score: 78.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark Williams</td>\n",
       "      <td>CHA</td>\n",
       "      <td>3PM</td>\n",
       "      <td>0 - 0 - 0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles Bridges</td>\n",
       "      <td>CHA</td>\n",
       "      <td>REB</td>\n",
       "      <td>4 - 7 - 9</td>\n",
       "      <td>68.49</td>\n",
       "      <td>[7, 11, 5, 12, 8, 9, 9, 7, 12, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark Williams</td>\n",
       "      <td>CHA</td>\n",
       "      <td>REB</td>\n",
       "      <td>7 - 11 - 14</td>\n",
       "      <td>67.77</td>\n",
       "      <td>[10, 14, 10, 8, 13, 12, 16, 12, 5, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Player team Stat   Stat Range  Confidence                            recentgames\n",
       "0  Mark Williams  CHA  3PM    0 - 0 - 0      100.00         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1  Miles Bridges  CHA  REB    4 - 7 - 9       68.49      [7, 11, 5, 12, 8, 9, 9, 7, 12, 7]\n",
       "2  Mark Williams  CHA  REB  7 - 11 - 14       67.77  [10, 14, 10, 8, 13, 12, 16, 12, 5, 9]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 6: total confidence score: 81.38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>LAC</td>\n",
       "      <td>3PM</td>\n",
       "      <td>0 - 0 - 0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>LAC</td>\n",
       "      <td>REB</td>\n",
       "      <td>8 - 11 - 13</td>\n",
       "      <td>73.11</td>\n",
       "      <td>[6, 14, 11, 14, 14, 11, 10, 10, 16, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>LAC</td>\n",
       "      <td>PTS</td>\n",
       "      <td>13 - 19 - 24</td>\n",
       "      <td>71.02</td>\n",
       "      <td>[25, 29, 17, 20, 21, 33, 21, 17, 25, 25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0    Ivica Zubac  LAC  3PM     0 - 0 - 0      100.00            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1    Ivica Zubac  LAC  REB   8 - 11 - 13       73.11   [6, 14, 11, 14, 14, 11, 10, 10, 16, 10]\n",
       "2  Kawhi Leonard  LAC  PTS  13 - 19 - 24       71.02  [25, 29, 17, 20, 21, 33, 21, 17, 25, 25]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 7: total confidence score: 62.88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>LAC</td>\n",
       "      <td>AST</td>\n",
       "      <td>5 - 9 - 12</td>\n",
       "      <td>63.14</td>\n",
       "      <td>[7, 11, 17, 11, 7, 5, 15, 8, 9, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>LAC</td>\n",
       "      <td>PTS</td>\n",
       "      <td>13 - 21 - 28</td>\n",
       "      <td>62.75</td>\n",
       "      <td>[25, 24, 25, 29, 27, 50, 21, 13, 18, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>LAC</td>\n",
       "      <td>PTS</td>\n",
       "      <td>11 - 18 - 24</td>\n",
       "      <td>62.75</td>\n",
       "      <td>[18, 26, 19, 22, 16, 22, 35, 12, 27, 10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0  James Harden  LAC  AST    5 - 9 - 12       63.14        [7, 11, 17, 11, 7, 5, 15, 8, 9, 6]\n",
       "1  James Harden  LAC  PTS  13 - 21 - 28       62.75  [25, 24, 25, 29, 27, 50, 21, 13, 18, 30]\n",
       "2   Ivica Zubac  LAC  PTS  11 - 18 - 24       62.75  [18, 26, 19, 22, 16, 22, 35, 12, 27, 10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 8: total confidence score: 65.14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collin Sexton</td>\n",
       "      <td>UTA</td>\n",
       "      <td>PTS</td>\n",
       "      <td>11 - 17 - 22</td>\n",
       "      <td>67.73</td>\n",
       "      <td>[8, 22, 16, 17, 16, 13, 2, 22, 19, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isaiah Collier</td>\n",
       "      <td>UTA</td>\n",
       "      <td>PTS</td>\n",
       "      <td>6 - 10 - 13</td>\n",
       "      <td>64.80</td>\n",
       "      <td>[16, 11, 8, 13, 6, 19, 11, 11, 11, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lauri Markkanen</td>\n",
       "      <td>UTA</td>\n",
       "      <td>PTS</td>\n",
       "      <td>10 - 17 - 23</td>\n",
       "      <td>62.90</td>\n",
       "      <td>[16, 14, 23, 5, 20, 32, 17, 20, 16, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player team Stat    Stat Range  Confidence                              recentgames\n",
       "0    Collin Sexton  UTA  PTS  11 - 17 - 22       67.73   [8, 22, 16, 17, 16, 13, 2, 22, 19, 30]\n",
       "1   Isaiah Collier  UTA  PTS   6 - 10 - 13       64.80    [16, 11, 8, 13, 6, 19, 11, 11, 11, 9]\n",
       "2  Lauri Markkanen  UTA  PTS  10 - 17 - 23       62.90  [16, 14, 23, 5, 20, 32, 17, 20, 16, 12]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 9: total confidence score: 77.60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>MIN</td>\n",
       "      <td>3PM</td>\n",
       "      <td>0 - 0 - 0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>MIN</td>\n",
       "      <td>REB</td>\n",
       "      <td>6 - 9 - 11</td>\n",
       "      <td>67.16</td>\n",
       "      <td>[12, 10, 8, 14, 8, 11, 10, 15, 13, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony Edwards</td>\n",
       "      <td>MIN</td>\n",
       "      <td>PTS</td>\n",
       "      <td>17 - 26 - 34</td>\n",
       "      <td>65.65</td>\n",
       "      <td>[28, 29, 25, 13, 29, 18, 44, 18, 17, 29]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0      Rudy Gobert  MIN  3PM     0 - 0 - 0      100.00            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1      Rudy Gobert  MIN  REB    6 - 9 - 11       67.16    [12, 10, 8, 14, 8, 11, 10, 15, 13, 16]\n",
       "2  Anthony Edwards  MIN  PTS  17 - 26 - 34       65.65  [28, 29, 25, 13, 29, 18, 44, 18, 17, 29]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 10: total confidence score: 65.43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>MIN</td>\n",
       "      <td>PTS</td>\n",
       "      <td>7 - 12 - 16</td>\n",
       "      <td>65.60</td>\n",
       "      <td>[12, 11, 16, 20, 12, 15, 13, 10, 19, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaden McDaniels</td>\n",
       "      <td>MIN</td>\n",
       "      <td>REB</td>\n",
       "      <td>3 - 6 - 8</td>\n",
       "      <td>65.51</td>\n",
       "      <td>[8, 8, 4, 6, 10, 3, 7, 10, 8, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaden McDaniels</td>\n",
       "      <td>MIN</td>\n",
       "      <td>PTS</td>\n",
       "      <td>11 - 17 - 22</td>\n",
       "      <td>65.18</td>\n",
       "      <td>[11, 16, 16, 13, 29, 17, 13, 20, 15, 27]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0      Rudy Gobert  MIN  PTS   7 - 12 - 16       65.60  [12, 11, 16, 20, 12, 15, 13, 10, 19, 16]\n",
       "1  Jaden McDaniels  MIN  REB     3 - 6 - 8       65.51         [8, 8, 4, 6, 10, 3, 7, 10, 8, 10]\n",
       "2  Jaden McDaniels  MIN  PTS  11 - 17 - 22       65.18  [11, 16, 16, 13, 29, 17, 13, 20, 15, 27]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 11: total confidence score: 73.77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>PTS</td>\n",
       "      <td>20 - 26 - 31</td>\n",
       "      <td>79.31</td>\n",
       "      <td>[34, 24, 19, 30, 37, 32, 26, 29, 28, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>REB</td>\n",
       "      <td>7 - 11 - 14</td>\n",
       "      <td>72.36</td>\n",
       "      <td>[10, 12, 17, 9, 11, 15, 12, 9, 19, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>MIL</td>\n",
       "      <td>PTS</td>\n",
       "      <td>15 - 22 - 28</td>\n",
       "      <td>69.63</td>\n",
       "      <td>[25, 22, 15, 22, 26, 34, 23, 28, 19, 22]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player team Stat    Stat Range  Confidence                               recentgames\n",
       "0  Giannis Antetokounmpo  MIL  PTS  20 - 26 - 31       79.31  [34, 24, 19, 30, 37, 32, 26, 29, 28, 27]\n",
       "1  Giannis Antetokounmpo  MIL  REB   7 - 11 - 14       72.36    [10, 12, 17, 9, 11, 15, 12, 9, 19, 10]\n",
       "2         Damian Lillard  MIL  PTS  15 - 22 - 28       69.63  [25, 22, 15, 22, 26, 34, 23, 28, 19, 22]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parlay 12: total confidence score: 62.02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Stat Range</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>recentgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>MIL</td>\n",
       "      <td>AST</td>\n",
       "      <td>3 - 5 - 6</td>\n",
       "      <td>63.63</td>\n",
       "      <td>[8, 10, 11, 4, 4, 5, 4, 6, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kyle Kuzma</td>\n",
       "      <td>MIL</td>\n",
       "      <td>REB</td>\n",
       "      <td>3 - 5 - 6</td>\n",
       "      <td>61.84</td>\n",
       "      <td>[8, 4, 4, 6, 8, 4, 10, 8, 9, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>AST</td>\n",
       "      <td>2 - 4 - 5</td>\n",
       "      <td>60.60</td>\n",
       "      <td>[7, 9, 7, 3, 4, 4, 10, 9, 7, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player team Stat Stat Range  Confidence                       recentgames\n",
       "0         Damian Lillard  MIL  AST  3 - 5 - 6       63.63  [8, 10, 11, 4, 4, 5, 4, 6, 4, 3]\n",
       "1             Kyle Kuzma  MIL  REB  3 - 5 - 6       61.84   [8, 4, 4, 6, 8, 4, 10, 8, 9, 6]\n",
       "2  Giannis Antetokounmpo  MIL  AST  2 - 4 - 5       60.60   [7, 9, 7, 3, 4, 4, 10, 9, 7, 6]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# display(results_reb)\n",
    "# display(results_ast)\n",
    "# display(results_pts)\n",
    "# display(results_3pm)\n",
    "\n",
    "df_merged = results_reb.merge(results_ast, on=['Player', 'team'], suffixes=('_reb', '_ast')) \\\n",
    "    .merge(results_pts, on=['Player', 'team'], suffixes=('_pts','extra_pts')) \\\n",
    "    .merge(results_3pm, on=['Player', 'team'], suffixes=('_pts','_3pm'))\n",
    "\n",
    "['Player', 'REB', 'confidence_level_REB', 'middlebet_REB', 'AST', 'confidence_level_AST', 'middlebet_AST', 'PTS', 'confidence_level_PTS', 'middlebet_PTS', '3PM', 'confidence_level_3PM', 'middlebet_3PM']\n",
    "\n",
    "# print(df_merged.columns)\n",
    "\n",
    "\n",
    "# df_merged['middlebet_PTS+REB'] = 0000\n",
    "\n",
    "# df_merged['PTS+REB'] = df_merged[['middlebet_PTS', 'middlebet_REB']].sum(axis=1)\n",
    "# df_merged['confidence_level_PTS+REB']=  round(df_merged[['confidence_level_PTS','confidence_level_REB']].sum(axis=1)/2,2)\n",
    "# df_merged = df_merged.rename(columns={'FGA': 'PTS'})\n",
    "# display(df_merged)\n",
    "# display(df_merged[['Player','confidence_level_PTS+REB']])\n",
    "\n",
    "\n",
    "from parlay_picker import create_parlays\n",
    "\n",
    "num_groups = 100  # Number of parlays you want to generate\n",
    "players_per_group = 3  # Number of players in each parlay\n",
    "min_confidence = 60\n",
    "\n",
    "parlays_df, group_confidence_scores = create_parlays(df_merged, num_groups, players_per_group,min_confidence)\n",
    "\n",
    "\n",
    "# Display the confidence scores for each group\n",
    "print(\"Confidence scores for each group:\")\n",
    "for group, score in group_confidence_scores:\n",
    "    print(f\"{group}: {score:.2f}\")\n",
    "\n",
    "\n",
    "# Display the DataFrames for each parlay and their confidence scores\n",
    "for (parlay_name, score), parlay_df in zip(group_confidence_scores, parlays_df):\n",
    "    print(\"\\n\")\n",
    "    print(f\"{parlay_name}: total confidence score: {score:.2f}\")\n",
    "    display(parlay_df)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
